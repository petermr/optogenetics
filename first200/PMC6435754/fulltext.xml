<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6435754</article-id><article-id pub-id-type="publisher-id">41349</article-id><article-id pub-id-type="doi">10.1038/s41598-019-41349-0</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Reverse-Correlation Analysis of the Mechanosensation Circuit and Behavior in <italic>C</italic>. <italic>elegans</italic> Reveals Temporal and Spatial Encoding</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Porto</surname><given-names>Daniel A.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Giblin</surname><given-names>John</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Yiran</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Lu</surname><given-names>Hang</given-names></name><address><email>hang.lu@gatech.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 4943</institution-id><institution-id institution-id-type="GRID">grid.213917.f</institution-id><institution>Interdisciplinary Bioengineering Program, </institution><institution>Georgia Institute of Technology, </institution></institution-wrap>Atlanta, USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 4943</institution-id><institution-id institution-id-type="GRID">grid.213917.f</institution-id><institution>Wallace H. Coulter Department of Biomedical Engineering, </institution><institution>Georgia Institute of Technology and Emory University, </institution></institution-wrap>Atlanta, USA </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 4943</institution-id><institution-id institution-id-type="GRID">grid.213917.f</institution-id><institution>School of Chemical &#x00026; Biomolecular Engineering, </institution><institution>Georgia Institute of Technology, </institution></institution-wrap>Atlanta, USA </aff></contrib-group><pub-date pub-type="epub"><day>26</day><month>3</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>26</day><month>3</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>9</volume><elocation-id>5182</elocation-id><history><date date-type="received"><day>29</day><month>6</month><year>2018</year></date><date date-type="accepted"><day>4</day><month>3</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Animals must integrate the activity of multiple mechanoreceptors to navigate complex environments. In <italic>Caenorhabditis elegans</italic>, the general roles of the mechanosensory neurons have been defined, but most studies involve end-point or single-time-point measurements, and thus lack dynamic information. Here, we formulate a set of unbiased quantitative characterizations of the mechanosensory system by using reverse correlation analysis on behavior. We use a custom tracking, selective illumination, and optogenetics platform to compare two mechanosensory systems: the gentle-touch (TRNs) and harsh-touch (PVD) circuits. This method yields characteristic linear filters that allow for the&#x000a0;prediction of behavioral responses. The resulting filters are consistent with previous findings and further provide new insights on the dynamics and spatial encoding of the systems. Our results suggest that the tiled network of the gentle-touch neurons has better resolution for spatial encoding than the harsh-touch neurons. Additionally, linear-nonlinear models can predict behavioral responses based only on sensory neuron activity. Our results capture the overall dynamics of behavior induced by the activation of sensory neurons, providing simple transformations that quantitatively characterize these systems. Furthermore, this platform can be extended to capture the behavioral dynamics induced by any neuron or other excitable cells in the animal.</p></abstract><funding-group><award-group><funding-source><institution>US National Institutes of Health</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">A key function of the nervous system is to integrate the activity from a variety of sensory neurons and transform these neuronal signals into specific behavioral responses. This integration occurs not only across sensory modalities but also spatially and temporally within a single modality such as in mechanosensation<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Characterizations of how the nervous system processes this information is vital for understanding brain function and allowing for prediction of behavioral responses. <italic>Caenorhabditis elegans</italic>, a nematode with a mapped connectome and powerful genetic and physiological tools, is an effective model organism for investigating relationships between sensory inputs and downstream activities<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. The components of the neural circuits involved in <italic>C</italic>. <italic>elegans</italic> mechanosensation have been elucidated through various genetic and behavioral analyses, coupled with neuronal cell ablation assays<sup><xref ref-type="bibr" rid="CR4">4</xref>&#x02013;<xref ref-type="bibr" rid="CR6">6</xref></sup>. Two sets of mechanoreceptors are specifically responsible for sensing touch throughout the body: the gentle touch sensing TRNs and harsh touch sensing PVDs<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. These specific neurons have been the focus of a number of studies, including genetic dissections of the mechanical signal transduction, their calcium responses and the eventual behavioral outcomes<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR8">8</xref>&#x02013;<xref ref-type="bibr" rid="CR15">15</xref></sup>. However, most descriptions are specific to a single input stimulus, typically a single pulse with an eye lash or a metal pick, and a single behavioral output. This leaves unexplored space of the stimuli and outputs, leading to descriptions that are potentially biased toward a specific stimulus, and not allowing for the generalizable prediction of the system.</p><p id="Par3">To map the transformations between mechanoreceptor neurons and behavioral outputs, we sought to model these transformations in an unbiased quantitative framework that captures the systems&#x02019; dynamics in a predictive manner. This is computationally challenging because of the stochasticity and complexity of the animal&#x02019;s behavioral repertoire, as well as the various time scales and frequencies relevant in the system<sup><xref ref-type="bibr" rid="CR16">16</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref></sup>. A successful technique for characterizing neuronal systems is reverse correlation analysis with a white noise stimulus<sup><xref ref-type="bibr" rid="CR19">19</xref>&#x02013;<xref ref-type="bibr" rid="CR26">26</xref></sup>. This methodology is commonly applied in sensory physiology to model a sensory neuron&#x02019;s response to natural stimuli as a linear filter. The computed linear filters provide a complete description of the linear dynamics of the neuron, and can be used in conjunction with a nonlinear filter to accurately model its function<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR27">27</xref>&#x02013;<xref ref-type="bibr" rid="CR30">30</xref></sup>. This technique has also been extended to modeling sensory neurons<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> and behavior in invertebrates<sup><xref ref-type="bibr" rid="CR32">32</xref>&#x02013;<xref ref-type="bibr" rid="CR36">36</xref></sup>. However, this technique has not been extended to model and contrast the spatial and temporal properties of behavioral responses to the gentle and harsh touch mechanosensory neurons.</p><p id="Par4">Although reverse correlation analysis allows for accurate estimations of system dynamics, several experimental obstacles hinder its applicability to the mechanosensory circuits in <italic>C</italic>. <italic>elegans</italic> at present. Current techniques for delivering precise mechanical stimuli to animals involve the delivery of a mechanical force via a stylus or microfluidic device to specific locations on the animal&#x02019;s body<sup><xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup>. Although ideal for neuronal imaging, these techniques require the immobilization of animals with glue or other techniques, and therefore, do not allow for reverse correlation analysis with behavior response dynamics. Additionally, many of these techniques have a low experimental throughput, and cannot provide the large sample sizes required for reverse correlation studies. One technique that overcomes these challenges is to couple optogenetics with behavior, as a light stimulus is more easily controlled and can be used to activate specific neurons in freely moving animals<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>. This fictive stimulus has the added benefit of bypassing differences in native receptor protein expressions, allowing for comparison between sensory systems. In order to apply light stimuli with spatial resolution to activate specific regions of sensory neurons, we adapted a previously developed tracking platform with selective illumination<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. The custom microscopy system uses a projector and computer vision tools to track the animal&#x000a0;in real-time, allowing for the delivery of spatially and temporally resolved stimuli required for white noise signal delivery.</p><p id="Par5">Combining these tools, we developed an experimental and computational pipeline for performing white noise analysis on <italic>C</italic>. <italic>elegans</italic>, and apply this method to elucidate models of transformations between mechanosensory neuron activity and behavioral response. Using our platform, we computed linear filters that characterize the dynamics of the gentle touch sensing TRNs and harsh touch sensing PVDs. These filters provide a quantitative framework for the functions of these neurons and allowed for the investigation of differences in spatial encoding. Furthermore, this technique&#x000a0;allowed us to create models that accurately predict behavioral changes in response to mechanosensory neuron activity. Our method provides simple transformations that quantitatively characterize these systems by capturing the spatiotemporal dynamics of behaviors induced by optogenetic activation of sensory neurons.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Reverse-correlation analysis using optogenetics and behavior tracking</title><p id="Par6">To illuminate the differences between the mechanosensory systems, we characterize and compare the dynamics for these two anatomically distinct sets of mechanosensory neurons: the gentle touch sensing TRNs and the harsh touch sensing PVDs (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1A</xref>). In order to use reverse correlation for modeling behavioral responses, the two main experimental requirements are the precise&#x000a0;delivery of a white noise stimulus and accurate measurements of the output. For the stimulus, we used optogenetics to directly activate the mechanosensory neurons with a white noise signal. This unmediated input enabled us to activate neurons regardless of expression of mechanotransductive channels. This allows&#x000a0;for the comparison of how the two systems and their morphologies control downstream activity, rather than differences in their sensory activation. Additionally, whereas a natural stimulus can activate additional sensory neurons and possibly interfere with characterization, the optogenetic stimulus will only activate the neurons expressing channelrhodopsin. Therefore, the resulting filters characterize the dynamics of behaviors exclusively in response to activation of specific sensory neurons. Our tracking platform<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> enables the delivery of patterned illumination while simultaneously tracking individual animals, allowing for selective activation of specific sections of transgenic animals with high spatial and temporal precision (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1B</xref>, Movie&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>, Methods). We used this platform to deliver the white noise light stimulus for reverse correlation; we activated mechanosensory neurons with a pseudo-random m-sequence pattern, a spectrally unbiased binary signal (Methods).<fig id="Fig1"><label>Figure 1</label><caption><p>Reverse correlation analysis of mechanosensory neurons enabled by tracking and selective illumination platform. (<bold>A</bold>) Mechanosensory neurons characterized in this study. The gentle touch sensing neurons ALML/R, AVM, PVM, and PLML/R (blue) and harsh touch sensing neurons PVDL/R (red). (<bold>B</bold>) Schematic of custom tracking system with selective illumination used for reverse correlation experiments (Methods). A projector is used as the light source to enable selective illumination. Captured video frames are processed in real-time to deliver accurate light patterns on moving animals. (<bold>C</bold>) Sample stimulus and extracted quantified behavior traces obtained from the custom platform and analysis script (Methods). Input is a binary signal of On and Off. Outputs are characterized for both &#x0201c;discrete&#x0201d; and &#x0201c;continuous&#x0201d; behaviors. Discretized behaviors are classified based on a custom behavior analysis script (Methods). Colors represented in sample output: dark blue represents a pause, red represent reversals, light blue represents turns. (<bold>D</bold>) A sample filter computed using the BWA computation (Acceleration Response to Anterior TRN, n&#x02009;=&#x02009;113 animals). Shaded area represents SEM. (<bold>E</bold>) The speed of convergence for the BWA as a function of the amount of data used to train the model. The error converges to a relative tolerance of &#x003b4;&#x02009;&#x0003c;&#x02009;0.005 after 30,000 time-points.</p></caption><graphic xlink:href="41598_2019_41349_Fig1_HTML" id="d29e419"/></fig></p><p id="Par7">The outputs we sought to characterize are the behavioral responses of animals using the optogenetic stimuli as inputs. We developed a custom computer vision algorithm (Methods) to analyze recordings of animals&#x02019; behavior in a high-throughput and unbiased manner. The worm&#x02019;s posture and position are extracted for each frame, which are then used to quantify various &#x0201c;continuous&#x0201d; behaviors such as instantaneous velocity, instantaneous head angle, and instantaneous acceleration (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1C</xref>). In addition to these &#x0201c;continuous&#x0201d; behaviors we also quantified and categorized several classical &#x0201c;discrete&#x0201d; behaviors such as reversals, pauses, and omega turns<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR40">40</xref>&#x02013;<xref ref-type="bibr" rid="CR42">42</xref></sup> (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1C</xref>, Methods). Each of these continuous and discrete variables was used as a separate output for reverse correlation analysis, yielding a filter that can be used to predict behavior responses to any arbitrary stimulus patterns. By using filters for a large portion of the worm&#x02019;s behavioral repertoire, we can describe the overall behavioral response when stimulating specific mechanosensory neurons.</p><p id="Par8">Using the white noise light stimulus for optogenetics and the quantified behavioral responses, we next applied&#x000a0;reverse correlation to model <italic>C</italic>. <italic>elegans</italic> responses as transformations of linear and non-linear filters. Classically, when characterizing mammalian neuronal systems, a neuron&#x02019;s response is modeled by computing the average of the stimuli that preceded its action potentials (spike-triggered average or STA) or its subthreshold voltages (voltage-weighted average or VWA)<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Analogously, we estimate the dynamics of <italic>C</italic>. <italic>elegans</italic> responses by computing the behavior weighted average of the stimulus (BWA). When stimulating specific segments of the mechanosensory systems, the BWA represents how the animals characteristically transform patterns of activity of those neurons into specific behaviors, providing a filter estimation of this transformation (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1D</xref>).</p><p id="Par9">In order to accurately estimate these linear filters, a large sample size is required to test enough input values<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR30">30</xref></sup>. To estimate the number of samples required in our system, we characterized the speed of convergence of computed filters as the number of input samples increased (Movie&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>). We characterized the convergence of filters by computing the L2 norm of the difference between subsequent filters (computed as the absolute difference between filters). We found that our system converges (to a relative tolerance of &#x003b4;&#x02009;&#x0003c;&#x02009;0.005) after using roughly 30,000 frames of tracking data (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1E</xref>). With our experimental conditions, this is equivalent to a sample size of roughly 30 animals (Methods).</p></sec><sec id="Sec4"><title>Linear Filters for anterior and posterior touch receptor neurons (TRNs) robustly capture behavioral dynamics</title><p id="Par10">We first used our method to characterize responses to the touch receptor neurons (TRNs: ALML/R, AVM, PVM, and PLML/R) by using transgenic animals expressing channelrhodopsin (ChR2) under the <italic>mec-4</italic> promotor (Methods)<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. In response to natural stimuli, the posterior TRNs (PVM and PLML/R) respond to posterior touch, inducing forward acceleration, whereas the anterior TRNs (ALML/R and AVM) respond to anterior touch, inducing reversals<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>. To characterize the dynamics of these responses, we applied an m-sequence light stimulus to either the anterior or posterior region of transgenic animals, selectively stimulating the anterior or posterior TRNs, respectively (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2A</xref>). We first computed linear filters characterizing the relationship between anterior TRNs and either discrete or continuous behavior (Figs&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="MOESM1" ref-type="media">S1</xref>). As a control, we also performed experiments with animals that were not fed all trans-retinol (ATR), a cofactor required for ChR2 function. The computed filters for control animals are flat, zero-mean signals (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, gray lines). In contrast, the acceleration BWA for the ATR-fed worms results in a filter with a robust negative peak, &#x02212;13&#x02009;&#x000b1;&#x02009;0.50&#x02009;&#x000b5;m/s<sup>2</sup> (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2B,Ei</xref>). This deceleration is expected from typical reversal responses to anterior touch stimulation<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>. The presence of this peak in the experimental group and its absence in the control group suggest that the filter is optogenetically induced, and not due to spontaneous behavior. We attribute small fluctuations as experimental noise rather than representing a true high frequency response. In addition&#x000a0;to peak magnitudes, our method also reveals new information about the dynamics of these responses. From the BWA, we can characterize metrics such as the delay to the peak (0.2&#x02009;s) and the decay timescale of the filter (0.4&#x02009;s). These temporal characteristics are critical for accurately predicting response to activation of the anterior TRNs.<fig id="Fig2"><label>Figure 2</label><caption><p>Linear filters for the touch receptor neurons (TRNs) responses are robust and reproducible. (<bold>A</bold>) Stimulus patterns and neurons being analyzed. Animals used in these experiments express channelrhodopsin using the mec-4 promoter (Methods). (<bold>B</bold>&#x02013;<bold>D</bold>) Linear filters computed from BWA for acceleration when stimulating the anterior (<bold>B</bold>,<bold>C</bold>) or posterior (<bold>D</bold>) TRNs. Statistical significance of filters determined by comparison with shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S4</xref>, ***top 1%, and not significant otherwise). (<bold>E</bold>) Comparisons of peak values from computed linear filters in B&#x02013;D. (<bold>F</bold>&#x02013;<bold>H</bold>) Linear filters computed from BWA for pauses and reversals when stimulating the anterior (<bold>F</bold>,<bold>G</bold>) and the posterior (<bold>H</bold>) TRNs with an m-sequence. (<bold>I</bold>) Comparisons of peak values from computed linear filters in F&#x02013;H. Colored plots represent filters computed from ATR-fed animals, black plots represent filters computed from control (not ATR-fed) animals. Dark line and light shade represent BWA and SEM, respectively (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). Error bars in bar plots indicate SEM (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). SEM was computed using number of animals as the sample size. Statistical significance determined by comparing peak magnitudes using student&#x02019;s t-test (***p&#x02009;&#x0003c;&#x02009;0.001).</p></caption><graphic xlink:href="41598_2019_41349_Fig2_HTML" id="d29e590"/></fig></p><p id="Par11">In order to further assess the validity of the resulting filters, we performed statistical tests comparing true filters and filters computed from shuffled data (Methods). We computed magnitudes for all filters, defined as the L2 norm, to the correctly computed filter. Data is shuffled in four different ways (Methods). In all tests, the BWA computed from experimental data has the highest magnitude compared to filters computed from shuffled data (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>). Together with the statistical comparison of ATR-fed and non ATR-fed animals, we conclude that the BWA for acceleration is robust and descriptive of the behavioral response.</p><p id="Par12">To ensure that the computed linear filters are not an artifact from the input signal itself, we tested computing filters using a different m-sequence stimulus. Using acceleration as an example, we observe a similar linear filter to those obtained with the previous stimulus (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2C</xref>, as compared to <xref rid="Fig2" ref-type="fig">2B</xref>). When comparing the peak values of the filters computed with different stimuli, there is no statistical difference (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2Eii</xref>). These results demonstrate that the linear filters are indeed characteristic of <italic>C</italic>. <italic>elegans</italic>&#x02019; behavioral output specifically in response to the activity in the anterior TRNs, and independent of the input signal.</p><p id="Par13">Next, we sought to compare the dynamics of the animals&#x02019; response between anterior or posterior TRN activities. Previous findings have shown that applying a mechanical force to the posterior region of the animal induces an acceleration, and PLM is required for these responses<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. As with the anterior TRNs, we stimulated the posterior TRNs by applying an m-sequence light stimulus to the posterior half of the animal, and computed the BWA for the same quantified behaviors (Figs&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="MOESM1" ref-type="media">S1</xref>). The filter for acceleration has a positive peak (2.8&#x02009;&#x000b1;&#x02009;0.48&#x02009;&#x000b5;m/s<sup>2</sup>), although with a much smaller magnitude than its anterior counterpart and is not statistically significant compared to non ATR-fed worms (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2D</xref>). Additionally, the filter is not statistically significant when testing against filters for shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S3</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S6</xref>). Interestingly, although the computed linear filter for the posterior TRNs has a peak in the direction that is consistent with previous findings, it is close to zero-mean. One interpretation that is consistent with literature is that worms have a lower rate of responses when activating PLM and PVM in comparison to the activating anterior TRNs. This is not surprising, as worms are generally moving forward and do not require a change in behavior to escape the weak stimulus, whereas avoidance of a weak anterior stimulus requires a directional change.</p><p id="Par14">In addition to continuous signals, we also estimated linear filters for the probability of transitions between defined states. Unlike in predicting continuous variables (e.g. acceleration and velocity), filters computed for these behaviors indicate a change in probability of transitions to these behaviors. When computing the BWA with transitions into pauses or reversals in response to anterior TRNs, we observe linear filters with positive peaks that are statistically significant as compared to non ATR-fed animals (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2F,G,I</xref>). Similarly, the filters computed from shuffled data support this statistical significance (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S3</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S6</xref>). This indicates that activating the TRNs induces an increase in probability of transitions to pauses or reversals, and this increased likelihood happens within the first second after a stimulus. In contrast, when stimulating the posterior TRNs, the filter computed for transitions into pauses and reversals is close to zero-mean, consistent with an interpretation whereby the stimulus does not alter these behaviors significantly (Figs&#x000a0;<xref rid="Fig2" ref-type="fig">2H,I</xref>, and <xref rid="MOESM1" ref-type="media">S3</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S6</xref>).</p></sec><sec id="Sec5"><title>Reverse correlation analysis of Harsh-Touch sensing PVD neurons</title><p id="Par15">In addition to the TRNs, <italic>C</italic>. <italic>elegans</italic> has another set of neurons that are responsible for body touch sensation. The PVD neurons are morphologically unique sensory neurons that have extensive and organized dendritic structures expanding most of the body of the worm; in contrast, TRNs are tiled (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1A</xref>). The PVD neurons are known to respond to harsh touch, as opposed to gentle touch or nose touch<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref></sup>. Because of the morphological and functional differences between the PVD and TRN systems, we ask whether there are downstream differences in spatial and temporal behavioral response dynamics. To do so, we applied the same reverse correlation method to animals expressing ChR2 in the PVD neurons<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>.</p><p id="Par16">For comparison with the TRNs, we again divided the stimulus regions into anterior and posterior segments and computed the BWA for the same behaviors (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3A</xref>). Interestingly, when the animal is stimulated either anteriorly or posteriorly, the BWA&#x02019;s for acceleration both have positive peaks (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3B,C</xref>). However, only the filters from the posterior segment are statistically different from the non-ATR group, with a higher positive peak for both acceleration (Anterior 4.0&#x02009;&#x000b1;&#x02009;0.58&#x02009;&#x000b5;m/s<sup>2</sup> vs Posterior 7.1&#x02009;&#x000b1;&#x02009;0.58&#x02009;&#x000b5;m/s<sup>2</sup>) and velocity (Anterior 3.5&#x02009;&#x000b1;&#x02009;0.32&#x02009;&#x000b5;m/s vs Posterior 7.1&#x02009;&#x000b1;&#x02009;0.32&#x02009;&#x000b5;m/s) (Figs&#x000a0;<xref rid="Fig3" ref-type="fig">3D</xref> and <xref rid="MOESM1" ref-type="media">S7</xref>). When computing the BWA with transitions into pauses or reversals in response to either anterior or posterior PVD, we observe flat, zero-mean linear filters (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3E,F</xref>). These filters are statistically indistinguishable from the non-ATR fed control group (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3G</xref>), suggesting that activation of the PVDs does not induce a change in probability of these events. When comparing these filters with shuffled data, only the posterior acceleration filter is statistically significant (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S8</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S11</xref>). This contrast from the TRN filters suggests a different role for PVD sensory neurons in the behavioral circuit &#x02013; that PVD activation promotes positive acceleration, and TRNs promote negative acceleration, consistent with previous findings<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>.<fig id="Fig3"><label>Figure 3</label><caption><p>Linear filters for PVD activity illuminate dynamic differences between gentle and harsh touch systems. (<bold>A</bold>) Stimulus patterns and PVD neurons being analyzed. (<bold>B</bold>,<bold>C</bold>) Linear filters computed from BWA for acceleration when stimulating the anterior (<bold>B</bold>) or posterior (C) regions of PVD. (<bold>D</bold>) Comparisons of peak values from computed filters. (<bold>E</bold>,<bold>F</bold>) Linear filters computed for pauses and reversals when stimulating the anterior (<bold>E</bold>) and posterior (<bold>F</bold>) regions. Statistical significance of filters determined by comparison with shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S8</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S9</xref>, ***Top 1%, and not significant otherwise). (<bold>G</bold>) Comparisons of peak values from computed filters. Colored plots represent filters computed from ATR-fed animals, black plots represent filters computed from control (not ATR-fed) animals. Dark line and light shade represent BWA and SEM, respectively (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). Error bars in bar plots indicate SEM (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). SEM was computed using number of animals as the sample size. Statistical significance determined by comparing peak magnitudes using student&#x02019;s t-test (***p&#x02009;&#x0003c;&#x02009;0.001).</p></caption><graphic xlink:href="41598_2019_41349_Fig3_HTML" id="d29e786"/></fig></p><p id="Par17">In addition to the magnitudes, the context of peak occurrence can also be informative. The PVD acceleration filters have significant negative peaks following the positive peaks; the magnitudes of the negative peaks are of similar values to the first positive peak (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3D</xref>). This suggests that the acceleration in response to PVD activation is more likely to occur when preceded by an absence of stimulus. In other words, acceleration is dependent on the derivative of the stimulus, not the absolute value. In contrast, the anterior TRN acceleration filters only contain one significant peak. These differences in the acceleration filters further supports the idea that PVD and TRNs influence different aspects of behavior.</p></sec><sec id="Sec6"><title>Linear-Nonlinear models predict behavioral response</title><p id="Par18">In general, the filters computed from BWA in response to a white noise signal capture the linear dynamics of the analyzed systems. However, biological systems are rarely linear<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. A common approach for modeling the nonlinear dynamics of a system is to use a linear-nonlinear cascade, where a static nonlinear filter is used to characterize the nonlinear dynamics not captured by reverse correlation<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR23">23</xref>&#x02013;<xref ref-type="bibr" rid="CR25">25</xref></sup>. To define static nonlinear filters, we used the linear filters computed from BWA and compared predicted outputs with measured experimental outputs (Methods). For instance, for acceleration in response to anterior TRNs, we first compared predicted values with the quantified experimental values (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4A</xref>, gray circles). Not surprisingly, there is a positive correlation between predicted and experimental outputs, indicating that the model does indeed capture linear dynamics in these responses. To capture the nonlinear dynamics of the response, we fit a static filter using a simple quadratic function (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4A</xref> blue lines, Methods). Similarly, we also characterized nonlinear filters for velocity (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S12</xref>) and transitions into pauses or reversals (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4B</xref>, Methods). The quadratic functions greatly improve the model fit to the data, suggesting that they capture a large portion of the nonlinear dynamics of the anterior TRNs.<fig id="Fig4"><label>Figure 4</label><caption><p>Static nonlinear filters capture nonlinear dynamics in behavioral outputs. Estimation of static filters to capture nonlinear dynamics. (<bold>A</bold>,<bold>B</bold>) Static nonlinear filters fitted using predicted values from the linear filter (x-axis) and experimental values (y-axis) when stimulating the anterior TRNs, for (<bold>A</bold>) acceleration and (<bold>B</bold>) transitions into pauses and reversals. Colored traces represent computed nonlinear filters and gray dots represent independent time-points from measured and predicted values. Probability of discrete events is computed as the probability of an event occurring at a given time point.</p></caption><graphic xlink:href="41598_2019_41349_Fig4_HTML" id="d29e844"/></fig></p><p id="Par19">We next sought to test the validity of using linear-nonlinear (LN) cascade models to predict behavioral responses to novel stimuli. To do this, we probed the anterior TRNs with a different m-sequence stimulus from the one used to compute the filters (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5A</xref>, Methods). We first compared the measured velocities of animals to the predicted velocities when using the linear filter only (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5B</xref>). Although the magnitude of predicted velocity from the model did not exactly match the experimental measurements, the model captures large features of the temporal dynamics of velocity in response to this novel stimulus. Next, we incorporated the static nonlinear filter to predict velocities (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5C</xref>). When using the LN model, the magnitudes of predicted velocities are more similar to experimental values, leading to more accurate predictions. In addition to predicting the continuous velocity of the animals, we also tested L and LN models for pauses and reversals, and observe predicted increases in probability of events similar to experimental values (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S13A,B</xref>). Incorporating the nonlinear component to these models also improves the model predictability.<fig id="Fig5"><label>Figure 5</label><caption><p>Linear-Nonlinear-Exponential (LNE) model accurately predicts behavioral response. (<bold>A</bold>) Block diagram of LNE model for used to predict behavioral responses to mechanosensory neuron activity: a LTI system modeled from BWA, followed by a static nonlinear filter and exponential decay filter. (<bold>B</bold>&#x02013;<bold>D</bold>) Predictions of velocity for L (<bold>B</bold>), LN (<bold>C</bold>), and LNE (<bold>D</bold>) models (blue) and experimental traces (black). For experimental data, dark line and shade represent average and SEM, respectively (n&#x02009;=&#x02009;31 animals). For model predictions, dark line represents model prediction and shaded area represents the 95% confidence interval (Methods). (<bold>E</bold>) Comparison of performance of models, computed as the sum of squared error (SSE) and normalized to the linear model performance value (Methods).</p></caption><graphic xlink:href="41598_2019_41349_Fig5_HTML" id="d29e889"/></fig></p><p id="Par20">Interestingly, in our experiments we observe a time-dependent decrease in the magnitude of responses, which fails to be captured in time-scales of the dynamic linear filters (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5B,C</xref> latter half). Biologically, this habituation of responses is commonly observed in sensory systems<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. In general, although LN models can predict system responses, this is true only to the time-scales captured in the linear filters, and does not capture adaptation dynamics. To model this decay of responses, we added a dynamic exponential function following the LN cascade (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5A</xref>). We tested a wide range of decay rate values using this model and found that a decay rate of 50&#x02009;s provided the best predictions (Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S14</xref>). Interestingly, this decay rate is consistent with previous findings from investigations of habituation to stimulation of TRNs, with both tapping and optogenetic stimuli<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. When adding this exponential component to our model, the accuracy of our model&#x02019;s predicted behavioral responses improves for later time points of the trials, thus improving the overall accuracy of our models (Figs&#x000a0;<xref rid="Fig5" ref-type="fig">5D</xref> and <xref rid="MOESM1" ref-type="media">S13C,D</xref>). These results illustrate how the linear filters computed from BWA, when combined with additional nonlinear filters, are powerful in predicting temporal dynamics of behavioral responses to sensory neuron activation and likely generalizable to other sensory responses.</p></sec><sec id="Sec7"><title>Spatially refined selective illumination improves resolution of linear filters from BWA</title><p id="Par21">We have thus far characterized mechanosensory systems by probing either the anterior or posterior segments of the animal, similar to previous investigations of the receptive fields of mechanosensory systems<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>. To further examine the spatial resolution of the mechanosensory systems, we took advantage of our selective-illumination light stimulus, which allows for the probing of specific spatial segments as small as 14&#x02009;&#x000b5;m<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. We characterized the TRN system with better resolution by increasing the number of segments in our stimulus to 4 (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6A</xref>). We applied an m-sequence stimulus selectively to one of the four segments, and computed linear filters for both continuous and discrete behavioral outputs (Figs&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="MOESM1" ref-type="media">S15</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S19</xref>). This particular discretization of the TRN system allows for the computation of separate filters for the processes and cell bodies of ALM and AVM, as well as separate filters for PVM and PLM cell bodies (while keeping a high number of photons in the stimulus region). We first computed filters for acceleration in response to stimulating four segments. The filters for the most anterior quarter and second-most anterior quarter have a prominent negative peak, statistically significant when compared to non-ATR fed animals (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6B,C,F</xref>). These filters are also statistically significant when compared to shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S16</xref>,<xref rid="MOESM1" ref-type="media">S17</xref>). Interestingly, these filters are similar to the filter computed from stimulating the entire anterior region (compare to Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2B,C</xref>). This suggests that there are no observable differences in acceleration dynamics between cell body and axon activity of the anterior TRNs.<fig id="Fig6"><label>Figure 6</label><caption><p>Decreasing the size of stimulus region allows for the estimation of a spatiotemporal receptive field with higher resolution. (<bold>A</bold>) Stimulus patterns used to analyze TRNs with improved spatial resolution. (<bold>B</bold>&#x02013;<bold>E</bold>) Linear filters computed for acceleration when stimulating the most anterior (<bold>B</bold>), the second-most anterior quarter (<bold>C</bold>), second-most posterior quarter (<bold>D</bold>), and the most posterior quarter (<bold>E</bold>) of the TRNs with an m-sequence. Statistical significance of filters determined by comparison with shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S16</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S17</xref>, ***Top 1%, **Top 2%, and not significant otherwise). (<bold>F</bold>) Comparisons of peak values from computed filters in B&#x02013;E. Error bars indicate SEM (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). (<bold>G</bold>&#x02013;<bold>J</bold>) Linear filters computed for acceleration when stimulating the most anterior (<bold>G</bold>), the second-most anterior quarter (<bold>H</bold>), second-most posterior quarter (<bold>I</bold>), and the most posterior quarter (<bold>J</bold>) of the TRNs with an m-sequence. Colored plots represent filters computed from ATR-fed animals, black plots represent filters computed from control (not ATR-fed) animals. Dark line and light shade represent BWA and SEM, respectively (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). (<bold>K</bold>) Comparisons of peak values from computed filters in <bold>B</bold>&#x02013;<bold>E</bold>. Error bars indicate SEM (sample sizes listed in Table&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>). SEM was computed using number of animals as the sample size. Statistical significance determined by comparing peak magnitudes using student&#x02019;s t-test (***p&#x02009;&#x0003c;&#x02009;0.001).</p></caption><graphic xlink:href="41598_2019_41349_Fig6_HTML" id="d29e1034"/></fig></p><p id="Par22">Not surprisingly, the filters for acceleration in response to the most posterior quarter and second most posterior quarter are both flat and are statistically indistinguishable from filters computed with non-ATR fed animals (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6D,E,F</xref>). These filters are also not statistically significant when comparing to shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S16</xref>,<xref rid="MOESM1" ref-type="media">S17</xref>). Similar to the anterior region, the acceleration filters for the separate posterior segments are similar to the flat filter computed from stimulating the entire posterior region (compare to Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2D</xref>).</p><p id="Par23">We next computed linear filters for transitions into pauses or reversals, and found differences in spatial encoding. The results for the anterior segments did not reveal much spatial encoding, with the filters for both the most anterior quarter and second-most anterior quarter both having positive peaks (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6G,H,K</xref>), similar to the filter computed when stimulating the entire anterior regions (compare to Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2F,H</xref>). These filters are also statistically significant when comparing to shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S16</xref>, <xref rid="MOESM1" ref-type="media">S17</xref>). This suggests that there is low spatial encoding of these discrete behavioral responses between the axons and cell bodies of the anterior TRNs. Interestingly, we observe different filters when dividing the posterior segment of the TRNs into separate segments for the cell bodies of PVM and PLM. The filter for the most posterior quarter, which includes the PLM cell body, is again a flat filter (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6J</xref>), similar to the filter computed when stimulating the entire posterior region (compare to 2&#x02009;H). Surprisingly, the filter for second-most posterior quarter has a negative peak, statistically significant when compared to non-ATR fed animals (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6I,K</xref>). This filter is also statistically significant when compared to shuffled data (Figs&#x000a0;<xref rid="MOESM1" ref-type="media">S16</xref>, <xref rid="MOESM1" ref-type="media">S17</xref>). The negative peak suggests that there is a reduced probability of pauses and reversals when activating PVM cell body. This suggests that PVM potentially has a previously undescribed function of inhibiting pauses and reversals. Additionally, the difference in filters for the four segments implies that the TRNs employ their tiled network to allow for spatial encoding of behavioral responses. This suggests that the morphological differences between the tiled TRNs and branched PVDs are used to differently control downstream activity.</p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par24">The nervous system continuously transduces sensory stimuli into neuronal activity and appropriate behavioral outputs. One of the biggest challenges in mapping this neuronal encoding is the lack of a quantitative framework for characterizing how a layer of neural activity is transduced into the downstream circuit. In this work, inspired by previous work in modeling neuronal systems, we built a framework that uses reverse correlation analysis with a custom tracking platform to analyze a <italic>C</italic>. <italic>elegans</italic> sensory system. We investigated the spatial and temporal encoding of two mechanosensory systems, the gentle touch sensing TRNs and the harsh touch sensing PVDs. We computed several linear filters that quantitatively describe transformations between sensory neuron activity and behavioral outputs, and support previous findings about the systems. Analysis of the PVDs produced linear filters that indicate an increase in velocity and acceleration from their activation, which is consistent with literature on its function<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref></sup>. Similarly, the linear filters computed for the TRNs were also consistent with previous literature: the anterior TRNs show decreases in velocity and acceleration, and an increase in probability of pauses and reversals<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>; additionally, the posterior TRNs induce a much smaller increase in acceleration in the positive direction<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR39">39</xref></sup>, and do not result in significant filters in our experimental conditions. In the present set of experiments, we did not select animals based on the coinjection marker expression (as a proxy for ChR2 expression in the neurons). The heterogeneity in the expression of ChR2 in the posterior TRNs, thus, is likely to introduce variation in the light-induced acceleration behavior, which resulted in the lack of statistical significance when quantitative filters are compared. In comparison, the anterior stimulation behavior is more robust; thus even in the presence of ChR2 expression heterogeneity, the quantitative filters do show statistical significance. When assuming uniform expression levels across the sensory systems, our results provide spatiotemporal receptive fields for these systems that are consistent with previous findings<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>.</p><p id="Par25">The linear filters resulting from our method provide several insights into the circuitry and morphological differences between the two sensory systems. First, although we used identical stimuli for both segments, the filters produced from activating the anterior TRNs were much more robust than the filters from activating the posterior TRNs, suggesting that downstream interneurons in this circuit are more responsive to the anterior neurons. This preference in downstream activity has also been observed in experiments involving tap responses, which show that reversals dominate over accelerations when tapping cultured plates, and this preference occurs downstream of sensory neuron activity<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. In contrast, the filters for the posterior segments of PVD were more robust than the anterior segments. This is also consistent with previous findings that show PVD is required for posterior harsh touch sensation, but not required for anterior harsh touch<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. A key difference in our experiments is that we bypass mechanoreceptor activation, and can therefore separate out effects due to differences in sensory neuron response to different spatial stimuli, as well as other neurons that might affect response rate. Therefore, one possible mechanism for the differential decision-making is that the two mechanosensory systems may have different strengths of connections to postsynaptic command interneurons. Particularly for PVD, although the number of physical synapses to forward command neuron PVC and backward command neuron AVA are similar<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>, the functional connectivity seems to be higher for PVC compared to AVA. Our results are consistent with this hypothesis.</p><p id="Par26">Our results also provide insight on the levels of spatial encoding in the TRNs and PVD systems. The TRNs, which employ a tiled network to cover the body, appear to have more spatial encoding. When comparing the computed filters for the anterior and posterior TRNs, both acceleration and reversals show distinct differences in responses. Furthermore, when analyzing this system in four segments, we observed differences in linear filters among the four segments. In contrast, the branched network in PVD does not appear to spatially encode behavioral responses. The filters from activating the anterior and posterior segments of the PVD system have similar dynamics, with the anterior filters having slightly smaller magnitudes and longer delays. This contrast between the two mechanosensory systems suggests that although both the TRNs and PVDs have spatially distributed processes to sense touch throughout the body, the unique morphological strategies in the two systems lead to differences in their capabilities of encoding responses. Biologically, this disparity in encoding can be explained by their morphologies and perhaps synaptic connectivity to downstream neurons, as the tiled TRN system consists of more nodes, which could allow for more spatially specific behavioral responses.</p><p id="Par27">One new finding from our experiments concerns the role of the cryptic PVM neuron. Although shown to respond to mechanical stimuli<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>, its role in mediating behavior is poorly understood<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR39">39</xref></sup>. We found that activating PVM did not induce significant changes in velocity. Interestingly, PVM activation significantly reduced the probability of reversal events. These filters suggest a unique function for PVM in modulating escape response. In contrast to the other TRNs, including PLM, PVM does not induce escape responses, but rather suppresses these behaviors. It should be noted that a segment of a PLM process is present in the same segment as the PVM cell body, and the resulting filters could represent a stimulation of both the PVM cell body and PLM process.</p><p id="Par28">The findings in this work demonstrate the utility of our method for providing new insights into the dynamics of the mechanosensory system in <italic>C</italic>. <italic>elegans</italic>, one of the earliest and better characterized neural circuits. By using a quantitative framework to compare the dynamics between the two sensory systems, we recapitulated qualitative findings from previous literature, and provide further insights in the temporal and spatial encoding in these systems. Additionally, we used linear filters computed from BWA to create LNE models that can predict the behavioral responses of animals in response to activity in sensory neurons alone. Because this method is noninvasive and independent of natural stimulus, it can be easily extended to investigate the dynamics of other neural circuits in <italic>C</italic>. <italic>elegans</italic> and other model organisms. We foresee many potential applications in investigations of sensory behavior responses and sensory integration.</p></sec><sec id="Sec9" sec-type="materials|methods"><title>Methods and Materials</title><sec id="Sec10"><title><italic>C</italic>. <italic>elegans</italic> culture and maintenance</title><p id="Par29">We used transgenic worms expressing channelrhodopsin in various mechanosensory neurons. Worm populations were cultured at 20C in the dark on standard nematode growth medium (NGM) petri dishes. Plates were coated with OP50 bacteria lawn supplemented with the cofactor required for channelrhodopsin, all-<italic>trans</italic>-retinal (Sigma-Aldrich). The solution was prepared by diluting a 50&#x02009;mM stock solution (in ethanol) in OP50 suspension to a final concentration of 100uM. Control animals were grown in parallel on OP50 without all-<italic>trans</italic>-retinal. All worms tested were F1 progeny of P0 adults picked onto seeded plates 3&#x02013;4 days before experiments. Animals were washed to unseeded NGM plates 1&#x02009;hr prior to assays. Animals were then picked to individual plates for experiments. Each animal was exposed to a single stimulus profile and then discarded. The strains used in this work included AQ2334: <italic>lite-1(ce314)</italic>; <italic>ljIs123[pmec-4::ChR2</italic>; <italic>punc-122::rfp</italic>]<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> and ZX899: <italic>lite-1(ce314)</italic>; <italic>ljIs123[pmec-4::ChR2; punc-122::rfp</italic>]<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>.</p></sec><sec id="Sec11"><title>Tracking and light delivery platform</title><p id="Par30">Experiments were performed on a tracking system adapted from a previously developed projector based microscopy system<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. The system uses an inverted microscope (Leica-DMIRB) with a low-magnification objective (x4) to image freely moving animals. We image using near-infrared light by applying a long-pass filter (715&#x02009;nm) to the transmitted light path and capture images using a large sensor NIR camera (Basler acA2040-180&#x02009;kmNIR), which limits interference in blue light used for optogenetics stimulus. A three-color LCD projector is used as the light source for optogenetic stimulus with selective illumination. We use a camera with large sensor area to capture the full body of the animal, and use a small ROI and binning to reduce the size of images to improve processing speed and therefore tracking rate. A Lenovo desktop computer with an Intel Core i74790 Processor (8&#x02009;MB Cache, up to 4.0&#x02009;GHz) and a 512&#x02009;GB Solid State Drive and 16&#x02009;GB RAM was used to process images for tracking and selective illumination. Tracking of individual animals was performed by using images taken with the camera, and processed to compute the centroid of the animal in terms of x-y pixels on the camera FOV. Based on the position of the computed centroid, a command is sent to a motorized stage to move the animal to the center of the FOV. To apply a light stimulus with spatial and temporal control, we used a modified projector as the light source to the microscope. Images taken with the camera are processed to determine the outline of the animal&#x02019;s body in each frame. The appropriate illumination pattern is then computed and sent to the projector. Stimuli were only presented when anterior and posterior segments were correctly computed by the algorithm; during pirouettes or other uncommon postures, stimulus presentation was paused. This process was performed at a rate of 13 frames per second. For each animal, illumination profile and tracking videos were saved for future analysis.</p></sec><sec id="Sec12"><title>Quantitative behavior analysis</title><p id="Par31">To extract quantitative behavioral features from tracking recordings, a custom MATLAB script was developed. A series of segmentation and morphological processes were used to extract body postures in each frame. We combined extracted postures with recorded stage movements to quantify several behaviors. We computed various &#x0201c;continuous&#x0201d; behaviors that have a scalar value for each time point. This includes velocity (magnitude), velocity (angle), acceleration, head angle, angular velocity. We also classified various &#x0201c;discrete&#x0201d; behaviors that have been used in previous works<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR40">40</xref>,<xref ref-type="bibr" rid="CR48">48</xref>,<xref ref-type="bibr" rid="CR49">49</xref></sup>. These include behaviors such as pauses, reversals, omega turns, and turns. Each of these behaviors were classified by applying thresholds on quantified continuous behaviors. Pauses and reversals were classified by applying both vertical and horizontal thresholds on velocity measurements. Omega turns were classified by applying a threshold on the eccentricity of the animal&#x02019;s posture. Curves were classified by applying a threshold on the angle of position trajectory.</p></sec><sec id="Sec13"><title>White noise experiments</title><p id="Par32">We used the selective illumination capability of the tracking system to deliver spatially controlled light stimuli to freely moving animals expressing ChR2 in their mechanosensory neurons. We used a pseudorandom m-sequence, a binary signal with unbiased spectrum, with similar properties to a Gaussian white noise signal<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. We tested several white noise signals, and found that an m-sequence with a maximum frequency of 2&#x02009;Hz produced reliable results, as it allows for testing time scales appropriate for behavioral responses (Negative results in Fig&#x000a0;<xref rid="MOESM1" ref-type="media">S20</xref>). We use a light intensity of 0.75&#x02009;mW/mm2 as it induces reliable and varying behavioral responses, similar to previous work<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. The generated pseudorandom sequences were repeats of a 6-bit words, 63 value length m-sequences (2*(2<sup>6</sup>&#x02009;&#x02212;&#x02009;1)&#x02009;=&#x02009;126 values). We deliver the same pseudorandom signal for each experimental group, applying the signal through the tracking system and changing values in the m-sequence at 2&#x02009;Hz, which is lower than the Nyquist Frequency (acquisition rate is 13&#x02009;Hz). Stimuli were only presented when ansterior and posterior segments were correctly computed by the tracking algorithm; during pirouettes or other uncommon postures, stimulus presentation was paused.</p></sec><sec id="Sec14"><title>Reverse correlation analysis</title><p id="Par33">To compute mathematical functions that describe the transformations from sensory neuronal activity into behavior, we first modeled the entire animal as a linear transducer:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$o(t)=h(t)\,\ast \,s(t)={\int }_{-\infty }^{\infty }h(\tau )s(t-\tau )d\tau $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>o</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mspace width="-.20em"/><mml:mo>&#x02217;</mml:mo><mml:mspace width="-.20em"/><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:msubsup><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:math><graphic xlink:href="41598_2019_41349_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where the relationship between the input signal (neuronal activity through optogenetics) s(t) and output signal (behavior) o(t) is characterized by a function h(t). We assume that the system is causal, and h(t)&#x02009;&#x0003c;&#x02009;0 for t&#x02009;&#x0003c;&#x02009;0. We used standard reverse-correlation similar to<sup><xref ref-type="bibr" rid="CR29">29</xref>&#x02013;<xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref></sup>, and computed h(t) for specific behaviors by computing a &#x0201c;behavior-weighted-average&#x0201d; (BWA):<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h(t) \sim BWA=\frac{1}{N}{\sum }_{\tau }\mathop{{S}_{\tau -t}}\limits^{}\times {v}_{o}(\tau )$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>~</mml:mo><mml:mi>B</mml:mi><mml:mi>W</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>&#x003c4;</mml:mi></mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mpadded lspace=".58em"><mml:mo mathsize="1.9em" stretchy="true">&#x021c0;</mml:mo></mml:mpadded></mml:mrow></mml:mover><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41598_2019_41349_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where the stimulus preceding each time-point is weighed by the scalar value of the behavior at that time. We convert the light stimulus patterns into &#x02212;1 and 1 for when the light is on and off, respectively. For continuous behaviors, we used the scalar values at each time points as the weights. For discrete behaviors, we used a binary signal indicating transitions from forward movement to specific states. For all cases, we compute linear filters using 400 points preceding and following each time point (801 total timepoints). The points preceding each time point are computed as a control to capture experimental variability.</p></sec><sec id="Sec15"><title>Statistical significance of computed filters</title><p id="Par34">Behavior-weighted averages (BWAs) were tested for significance by comparing their magnitude, computed as the L2 norm, to a distribution of random filters computed with shuffled data. We tested four different methods of shuffling data: cyclic shuffling of the stimulus vector by a random integer, cyclic shuffling of the output vector by a random integer, random permutations of the stimulus vector, and random permutations of the output vector. For each test, we perform the same computation with the shuffled data and repeat 100 times. For determining the significance of all computed filters, we performed the shuffling test using cyclic shuffling of the stimulus vector by a random integer. The BWA is classified as significant if its magnitude is higher than all shuffled data tests. Random integers were generated from a uniform distribution from 1 to length of vector using the MATLAB function rand, and random permutations of vectors were performed using the MATLAB function randperm.</p></sec><sec id="Sec16"><title>Nonlinear filters and model predictions</title><p id="Par35">We model static nonlinear filters for each behavioral response in order to extract the nonlinear dynamics not captured in the linear filters computed from reverse correlation<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. We first compute linear model predictions by convolving the computed linear filters from presented stimuli in each trial used, as shown in equation (<xref rid="Equ1" ref-type="">1</xref>). We then compare these linear predictions to the measured outputs at each time point, and fit a quadratic function. For &#x0201c;discrete&#x0201d; behaviors, probabilities for transitions into specific behaviors were calculated at each time point. These quadratic functions are then used as static nonlinear filters in a linear-nonlinear (LN) cascade model for specific behavior transformations.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{pN}({\rm{t}})={F}_{N}({y}_{pL})$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math><graphic xlink:href="41598_2019_41349_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where the predicted nonlinear output is a static function of the predicted linear output. We also apply an exponential decay filter (LNE) to capture nonlinear adaptations to the stimuli. We apply this exponential factor to only the changes in behavior after the stimulus:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{pE}(t &#x0003e; 5)=({y}_{pN}(t &#x0003e; 5)-{\rm{avg}}({y}_{pN}(t &#x0003c; 5))\ast \exp (\,-\,\,\lambda t)+{\rm{avg}}({y}_{pN}(t &#x0003c; 5))$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">avg</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02217;</mml:mo><mml:mi>exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mspace width="-.25em"/><mml:mo>&#x02212;</mml:mo><mml:mspace width="-.25em"/><mml:mspace width="-.25em"/><mml:mi>&#x003bb;</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">avg</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math><graphic xlink:href="41598_2019_41349_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where the decay parameter <inline-formula id="IEq1"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda $$\end{document}</tex-math><mml:math id="M10"><mml:mi>&#x003bb;</mml:mi></mml:math><inline-graphic xlink:href="41598_2019_41349_Article_IEq1.gif"/></alternatives></inline-formula> is 50&#x02009;s, based on empirical data (Fig&#x000a0;<xref rid="MOESM1" ref-type="media">S14</xref>) and previous findings<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. We use bootstrap sampling to compute 95% confidence intervals for our model predictions. Confidence intervals were computed using the MATLAB functions bootstrp and bootci, computed with 1000 resamples of the stimulus data.</p></sec><sec id="Sec17"><title>Statistics</title><p id="Par36">Linear filters are presented as mean&#x02009;&#x000b1;&#x02009;SEM as computed by the BWA. The two-tailed Student&#x02019;s t-test was used to compare filter peaks between two groups. Peaks were determined by searching for local maxima in the filters between &#x02212;1&#x02009;&#x0003c;&#x02009;t&#x02009;&#x0003c;&#x02009;1. P&#x02009;&#x0003c;&#x02009;0.005 was considered statistically significant. Accuracy of best-fit nonlinear filters were computed as coefficients of determination (R<sup>2</sup> values). Performance of models were compared using the sum of squared error (SSE). Values are normalized to the SSE value for linear models.</p></sec></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec19"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2019_41349_MOESM1_ESM.pdf"><caption><p>SI</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41598_2019_41349_MOESM2_ESM.avi"><caption><p>SV1</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="41598_2019_41349_MOESM3_ESM.avi"><caption><p>SV2</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p><bold>Supplementary information</bold> accompanies this paper at 10.1038/s41598-019-41349-0.</p></sec><ack><title>Acknowledgements</title><p>The authors gratefully acknowledge the funding support of the US National Institutes of Health (R01NS096581, R01GM088333, R21EB021676, and R21EB020424 to H.L.).</p></ack><notes notes-type="author-contribution"><title>Author Contributions</title><p>D.P. and H.L. designed experiments. D.P., J.G. and Y.Z. performed experiments. D.P.&#x000a0;and H.L. wrote the manuscript and D.P.&#x000a0;prepared all figures. All authors reviewed the manuscript.</p></notes><notes notes-type="data-availability"><title>Data Availability</title><p>All behavior and stimulus data generated during the current study are available from the corresponding author upon reasonable request.</p></notes><notes notes-type="data-availability"><title>Code Availability</title><p>All custom code used to generate results in this manuscript are available on Github (<ext-link ext-link-type="uri" xlink:href="https://github.gatech.edu/pages/dporto3/BWA-v1/">https://github.gatech.edu/pages/dporto3/BWA-v1/</ext-link>).</p></notes><notes notes-type="COI-statement"><sec id="FPar1"><title>Competing Interests</title><p>The authors declare no competing interests.</p></sec></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Kandel, E. R., Schwartz, J. H., Jessell, T. M., Siegelbaum, S. A. &#x00026; Hudspeth, A. J. <italic>Principles of Neural Science</italic>, <italic>Fifth Edition</italic>. <italic>Neurology</italic><bold>3</bold> (2014).</mixed-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JG</given-names></name><name><surname>Southgate</surname><given-names>E</given-names></name><name><surname>Thomson</surname><given-names>JN</given-names></name><name><surname>Brenner</surname><given-names>S</given-names></name></person-group><article-title>The Structure of The Nervous-System of the Nematode Caenorhabditis-Elegans</article-title><source>Philos. Trans. R. Soc. London Ser. B-Biological Sci.</source><year>1986</year><volume>314</volume><fpage>1</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1098/rstb.1986.0056</pub-id><pub-id pub-id-type="pmid">22462104</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname><given-names>P</given-names></name><name><surname>Samuel</surname><given-names>ADT</given-names></name></person-group><article-title>Caenorhabditis elegans: a model system for systems neuroscience</article-title><source>Curr. Opin. Neurobiol.</source><year>2009</year><volume>19</volume><fpage>637</fpage><lpage>643</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2009.09.009</pub-id><pub-id pub-id-type="pmid">19896359</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalfie</surname><given-names>M</given-names></name><etal/></person-group><article-title>The Neural Circuit for Touch Sensitivity in Caenorhabditis-Elegans</article-title><source>J. Neurosci.</source><year>1985</year><volume>5</volume><fpage>956</fpage><lpage>964</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.05-04-00956.1985</pub-id><pub-id pub-id-type="pmid">3981252</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Chalfie, M. &#x00026; Au, M. Genetic control of differentiation of the Caenorhabditis elegans touch receptor neurons. <italic>Science (80-</italic>.<italic>)</italic>. <bold>243</bold> (1989).</mixed-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wicks</surname><given-names>SR</given-names></name><name><surname>Rankin</surname><given-names>CH</given-names></name></person-group><article-title>Integration of mechanosensory stimuli in Caenorhabditis elegans</article-title><source>J. Neurosci.</source><year>1995</year><volume>15</volume><fpage>2434</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-03-02434.1995</pub-id><pub-id pub-id-type="pmid">7891178</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Goodman, M. B. Mechanosensation. <italic>WormBook</italic> 1&#x02013;14 (2006).</mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Wicks, S. R., Roehrig, C. J. &#x00026; Rankin, C. H. A Dynamic Network Simulation of the Nematode Tap Withdrawal Circuit: Predictions Concerning Synaptic Function Using Behavioral Criteria. <italic>J</italic>. <italic>Neurosci</italic>. <bold>16</bold> (1996).</mixed-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname><given-names>H</given-names></name><etal/></person-group><article-title><italic>In vivo</italic> imaging of C-elegans mechanosensory neurons demonstrates a specific role for the MEC-4 channel in the process of gentle touch sensation</article-title><source>Neuron</source><year>2003</year><volume>39</volume><fpage>1005</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2003.08.015</pub-id><pub-id pub-id-type="pmid">12971899</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albeg</surname><given-names>A</given-names></name><etal/></person-group><article-title>C-elegans multi-dendritic sensory neurons: Morphology and function</article-title><source>Mol. Cell. Neurosci.</source><year>2011</year><volume>46</volume><fpage>308</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1016/j.mcn.2010.10.001</pub-id><pub-id pub-id-type="pmid">20971193</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chatzigeorgiou</surname><given-names>M</given-names></name><etal/></person-group><article-title>Specific roles for DEG/ENaC and TRP channels in touch and thermosensation in C. elegans nociceptors</article-title><source>Nat. Neurosci.</source><year>2010</year><volume>13</volume><fpage>861</fpage><lpage>U106</lpage><pub-id pub-id-type="doi">10.1038/nn.2581</pub-id><pub-id pub-id-type="pmid">20512132</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Li, W., Kang, L., Piggott, B. J., Feng, Z. &#x00026; Xu, X. Z. S. The neural circuits and sensory channels mediating harsh touch sensation in Caenorhabditis elegans. <italic>Nat</italic>. <italic>Commun</italic>. <bold>2</bold> (2011).</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Husson</surname><given-names>SJ</given-names></name><etal/></person-group><article-title>Optogenetic Analysis of a Nociceptor Neuron and Network Reveals Ion Channels Acting Downstream of Primary Sensors</article-title><source>Curr. Biol.</source><year>2012</year><volume>22</volume><fpage>743</fpage><lpage>752</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.02.066</pub-id><pub-id pub-id-type="pmid">22483941</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Nekimken, A. L. <italic>et al</italic>. Pneumatic stimulation of C. elegans mechanoreceptor neurons in a microfluidic trap. <italic>Lab Chip</italic>, 10.1039/C6LC01165A (2017).</mixed-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Automated and controlled mechanical stimulation and functional imaging <italic>in vivo</italic> in C. elegans</article-title><source>Lab Chip</source><year>2017</year><volume>17</volume><fpage>2609</fpage><lpage>2618</lpage><pub-id pub-id-type="doi">10.1039/C7LC00465F</pub-id><pub-id pub-id-type="pmid">28660945</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>GJ</given-names></name><name><surname>de Mesquita</surname><given-names>MB</given-names></name><name><surname>Ryu</surname><given-names>WS</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name></person-group><article-title>Emergence of long timescales and stereotyped behaviors in Caenorhabditis elegans</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2011</year><volume>108</volume><fpage>7286</fpage><lpage>7289</lpage><pub-id pub-id-type="doi">10.1073/pnas.1007868108</pub-id><pub-id pub-id-type="pmid">21502536</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>AEX</given-names></name><name><surname>Yemini</surname><given-names>EI</given-names></name><name><surname>Grundy</surname><given-names>LJ</given-names></name><name><surname>Jucikas</surname><given-names>T</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name></person-group><article-title>A dictionary of behavioral motifs reveals clusters of genes affecting Caenorhabditis elegans locomotion</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2013</year><volume>110</volume><fpage>791</fpage><lpage>796</lpage><pub-id pub-id-type="doi">10.1073/pnas.1211447110</pub-id><pub-id pub-id-type="pmid">23267063</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yemini</surname><given-names>E</given-names></name><name><surname>Jucikas</surname><given-names>T</given-names></name><name><surname>Grundy</surname><given-names>LJ</given-names></name><name><surname>Brown</surname><given-names>AEX</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name></person-group><article-title>A database of Caenorhabditis elegans behavioral phenotypes</article-title><source>Nat. Methods</source><year>2013</year><volume>10</volume><fpage>877</fpage><lpage>+</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2560</pub-id><pub-id pub-id-type="pmid">23852451</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Abbott, P. D. and L. F. In (The MIT Press, 2001).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Simoncelli, E. P., Paninski, L., Pillow, J. &#x00026; Schwartz, O. <italic>Characterization of Neural Responses with Stochastic Stimuli</italic>. <italic>Cognitive Neurosciences Iii</italic>, <italic>Third Edition</italic> (2004).</mixed-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><article-title>A simple white noise analysis of neuronal light responses</article-title><source>Network-Computation Neural Syst.</source><year>2001</year><volume>12</volume><fpage>199</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1080/713663221</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname><given-names>D</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><article-title>Reverse correlation in neurophysiology</article-title><source>Cogn. Sci.</source><year>2004</year><volume>28</volume><fpage>147</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1207/s15516709cog2802_2</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharpee</surname><given-names>TO</given-names></name></person-group><article-title>Computational Identification of Receptive Fields</article-title><source>Annu. Rev. Neurosci. Vol 36</source><year>2013</year><volume>36</volume><fpage>103</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170253</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nykamp Siam</surname><given-names>J</given-names></name><name><surname>Appl Math</surname><given-names>DQ</given-names></name></person-group><article-title>White Noise Analysis of Coupled Linear-Nonlinear Systems *</article-title><source>Soc. Indiustrial Appl. Math.</source><year>2003</year><volume>63</volume><fpage>1208</fpage><lpage>1230</lpage><pub-id pub-id-type="doi">10.1137/S0036139901397571</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>IW</given-names></name><name><surname>Korenberg</surname><given-names>MJ</given-names></name></person-group><article-title>The identification of nonlinear biological systems: Wiener and Hammerstein cascade models</article-title><source>Biol. Cybern.</source><year>1986</year><volume>55</volume><fpage>135</fpage><lpage>144</lpage><?supplied-pmid 3801534?><pub-id pub-id-type="pmid">3801534</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakai</surname><given-names>HM</given-names></name></person-group><article-title>White-Noise Analysis in Neurophysiology</article-title><source>Physiol. Rev.</source><year>1992</year><volume>72</volume><fpage>491</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1152/physrev.1992.72.2.491</pub-id><pub-id pub-id-type="pmid">1557430</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bredfeldt</surname><given-names>CE</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name></person-group><article-title>Dynamics of spatial frequency tuning in macaque V1</article-title><source>J. Neurosci.</source><year>2002</year><volume>22</volume><fpage>1976</fpage><lpage>1984</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-05-01976.2002</pub-id><pub-id pub-id-type="pmid">11880528</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><article-title>Receptive-field dynamics in the central visual pathways</article-title><source>Trends Neurosci.</source><year>1995</year><volume>18</volume><fpage>451</fpage><lpage>458</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(95)94496-R</pub-id><pub-id pub-id-type="pmid">8545912</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>A</given-names></name><etal/></person-group><article-title>Spatiotemporal receptive fields of barrel cortex revealed by reverse correlation of synaptic input</article-title><source>Nat. Neurosci.</source><year>2014</year><volume>17</volume><fpage>866</fpage><lpage>875</lpage><pub-id pub-id-type="doi">10.1038/nn.3720</pub-id><pub-id pub-id-type="pmid">24836076</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behnia</surname><given-names>R</given-names></name><name><surname>Clark</surname><given-names>DA</given-names></name><name><surname>Carter</surname><given-names>AG</given-names></name><name><surname>Clandinin</surname><given-names>TR</given-names></name><name><surname>Desplan</surname><given-names>C</given-names></name></person-group><article-title>Processing properties of ON and OFF pathways for Drosophila motion detection</article-title><source>Nature</source><year>2014</year><volume>512</volume><fpage>427</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1038/nature13427</pub-id><pub-id pub-id-type="pmid">25043016</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>S</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Cho</surname><given-names>CE</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name></person-group><article-title>Temporal Responses of C. elegans Chemosensory Neurons Are Preserved in Behavioral Dynamics</article-title><source>Neuron</source><year>2014</year><volume>81</volume><fpage>616</fpage><lpage>628</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.020</pub-id><pub-id pub-id-type="pmid">24440227</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coen</surname><given-names>P</given-names></name><name><surname>Clemens</surname><given-names>J</given-names></name><name><surname>Weinstein</surname><given-names>A</given-names></name></person-group><article-title>Dynamic sensory cues shape song structure in Drosophila</article-title><source>Nature</source><year>2014</year><volume>507</volume><fpage>233</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1038/nature13131</pub-id><pub-id pub-id-type="pmid">24598544</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clemens</surname><given-names>J</given-names></name><etal/></person-group><article-title>Connecting Neural Codes with Behavior in the Auditory System of Drosophila</article-title><source>Neuron</source><year>2015</year><volume>87</volume><fpage>1332</fpage><lpage>1343</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.014</pub-id><pub-id pub-id-type="pmid">26365767</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernandez-Nunez</surname><given-names>L</given-names></name><etal/></person-group><article-title>Reverse-correlation analysis of navigation dynamics in Drosophila larva using optogenetics</article-title><source>Elife</source><year>2015</year><volume>4</volume><fpage>e06225</fpage><pub-id pub-id-type="doi">10.7554/eLife.06225</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gepner</surname><given-names>R</given-names></name><name><surname>Mihovilovic Skanata</surname><given-names>M</given-names></name><name><surname>Bernat</surname><given-names>NM</given-names></name><name><surname>Kaplow</surname><given-names>M</given-names></name><name><surname>Gershow</surname><given-names>M</given-names></name></person-group><article-title>Computations underlying Drosophila photo-taxis, odor-taxis, and multi-sensory integration</article-title><source>Elife</source><year>2015</year><volume>4</volume><fpage>e06229</fpage><pub-id pub-id-type="doi">10.7554/eLife.06229</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Liu, M., Sharma, A. K., Shaevitz, J. W. &#x00026; Leifer, A. M. Temporal processing and context dependency in Caenorhabditis elegans response to mechanosensation. <italic>Elife</italic><bold>7</bold> (2018).</mixed-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eastwood</surname><given-names>AL</given-names></name><etal/></person-group><article-title>Tissue mechanics govern the rapidly adapting and symmetrical response to touch</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2015</year><volume>112</volume><fpage>E6955</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1073/pnas.1514138112</pub-id><pub-id pub-id-type="pmid">26627717</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Shipley, F. B., Clark, C. M., Alkema, M. J. &#x00026; Leifer, A. M. Simultaneous optogenetic manipulation and calcium imaging in freely moving C-elegans. <italic>Front</italic>. <italic>Neural Circuits</italic><bold>8</bold> (2014).</mixed-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stirman</surname><given-names>JN</given-names></name><etal/></person-group><article-title>Real-time multimodal optical control of neurons and muscles in freely behaving Caenorhabditis elegans</article-title><source>Nat. Methods</source><year>2011</year><volume>8</volume><fpage>153</fpage><lpage>U78</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1555</pub-id><pub-id pub-id-type="pmid">21240278</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gray</surname><given-names>JM</given-names></name><name><surname>Hill</surname><given-names>JJ</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name></person-group><article-title>A circuit for navigation in Caenorhabditis elegans</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2005</year><volume>102</volume><fpage>3184</fpage><lpage>3191</lpage><pub-id pub-id-type="doi">10.1073/pnas.0409009101</pub-id><pub-id pub-id-type="pmid">15689400</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>W</given-names></name><name><surname>Cosman</surname><given-names>P</given-names></name><name><surname>Berry</surname><given-names>CC</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name></person-group><article-title>Automatic tracking, feature extraction and classification of C elegans phenotypes</article-title><source>IEEE Trans. Biomed. Eng.</source><year>2004</year><volume>51</volume><fpage>1811</fpage><lpage>1820</lpage><pub-id pub-id-type="doi">10.1109/TBME.2004.831532</pub-id><pub-id pub-id-type="pmid">15490828</pub-id></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albrecht</surname><given-names>DR</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name></person-group><article-title>High-content behavioral analysis of Caenorhabditis elegans in precise spatiotemporal chemical environments</article-title><source>Nat. Methods</source><year>2011</year><volume>8</volume><fpage>599</fpage><lpage>U120</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1630</pub-id><pub-id pub-id-type="pmid">21666667</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leifer</surname><given-names>AM</given-names></name><name><surname>Fang-Yen</surname><given-names>C</given-names></name><name><surname>Gershow</surname><given-names>M</given-names></name><name><surname>Alkema</surname><given-names>MJ</given-names></name><name><surname>Samuel</surname><given-names>ADT</given-names></name></person-group><article-title>Optogenetic manipulation of neural activity in freely moving Caenorhabditis elegans</article-title><source>Nat. Methods</source><year>2011</year><volume>8</volume><fpage>147</fpage><lpage>U71</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1554</pub-id><pub-id pub-id-type="pmid">21240279</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>JK</given-names></name><name><surname>Rankin</surname><given-names>CH</given-names></name></person-group><article-title>Analyses of habituation in Caenorhabditis elegans</article-title><source>Learn. Mem.</source><year>2001</year><volume>8</volume><fpage>63</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1101/lm.37801</pub-id><pub-id pub-id-type="pmid">11274251</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Timbers</surname><given-names>TA</given-names></name><name><surname>Giles</surname><given-names>AC</given-names></name><name><surname>Ardiel</surname><given-names>EL</given-names></name><name><surname>Kerr</surname><given-names>RA</given-names></name><name><surname>Rankin</surname><given-names>CH</given-names></name></person-group><article-title>Intensity discrimination deficits cause habituation changes in middle-aged Caenorhabditis elegans</article-title><source>Neurobiol. Aging</source><year>2013</year><volume>34</volume><fpage>621</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2012.03.016</pub-id><pub-id pub-id-type="pmid">22575357</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Altun, Z. F. <italic>et al</italic>. WormAtlas. at, <ext-link ext-link-type="uri" xlink:href="http://www.wormatlas.org">http://www.wormatlas.org</ext-link>.</mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Cho, Y. <italic>et al</italic>. High-Throughput Controlled Mechanical Stimulation and Functional Imaging <italic>In Vivo</italic>. <italic>bioRxiv</italic>, 10.1101/107318 (2017).</mixed-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>K-M</given-names></name><name><surname>Cosman</surname><given-names>P</given-names></name><name><surname>Schafer</surname><given-names>WR</given-names></name></person-group><article-title>Automated detection and analysis of foraging behavior in Caenorhabditis elegans</article-title><source>J. Neurosci. Methods</source><year>2008</year><volume>171</volume><fpage>153</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.01.027</pub-id><pub-id pub-id-type="pmid">18342950</pub-id></element-citation></ref><ref id="CR49"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsch</surname><given-names>J</given-names></name><name><surname>Ventimiglia</surname><given-names>D</given-names></name><name><surname>Bargmann</surname><given-names>CI</given-names></name><name><surname>Albrecht</surname><given-names>DR</given-names></name></person-group><article-title>High-throughput imaging of neuronal activity in Caenorhabditis elegans</article-title><source>Proc. Natl. Acad. Sci. USA</source><year>2013</year><volume>110</volume><fpage>E4266</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1073/pnas.1318325110</pub-id><pub-id pub-id-type="pmid">24145415</pub-id></element-citation></ref><ref id="CR50"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korenberg</surname><given-names>MJ</given-names></name><name><surname>Hunter</surname><given-names>IW</given-names></name></person-group><article-title>The Identification Of Nonlinear Biological-Systems - Lnl Cascade Models</article-title><source>Biol. Cybern.</source><year>1986</year><volume>55</volume><fpage>125</fpage><lpage>134</lpage><?supplied-pmid 3801533?><pub-id pub-id-type="pmid">3801533</pub-id></element-citation></ref></ref-list></back></article>