<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?all-math-mml yes?><?use-mml?><?properties open_access?><?properties manuscript?><?origin nihpa?><?iso-abbr Curr. Opin. Neurobiol.?><?submitter-system nihms?><?submitter-canonical-name Elsevier?><?submitter-canonical-id ELSEVIERAM?><?submitter-userid 8068823?><?submitter-authority myNCBI?><?submitter-login elsevieram?><?submitter-name Author support, Elsevier?><?domain nihpa?><front><journal-meta><journal-id journal-id-type="nlm-journal-id">9111376</journal-id><journal-id journal-id-type="pubmed-jr-id">2201</journal-id><journal-id journal-id-type="nlm-ta">Curr Opin Neurobiol</journal-id><journal-id journal-id-type="iso-abbrev">Curr. Opin. Neurobiol.</journal-id><journal-title-group><journal-title>Current opinion in neurobiology</journal-title></journal-title-group><issn pub-type="ppub">0959-4388</issn><issn pub-type="epub">1873-6882</issn></journal-meta><article-meta><article-id pub-id-type="pmcid">6095465</article-id><article-id pub-id-type="pmid">29505948</article-id><article-id pub-id-type="doi">10.1016/j.conb.2018.02.005</article-id><article-id pub-id-type="manuscript">nihpa961371</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>The biological and behavioral computations that influence dopamine responses</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Stauffer</surname><given-names>WR</given-names></name></contrib><aff id="A1">Department of Neurobiology, Systems Neuroscience Center, University of Pittsburgh, Pittsburgh, PA 15261, United States</aff></contrib-group><author-notes><corresp id="CR1">Corresponding author: Stauffer, WR (<email>wrs@pitt.edu</email>)</corresp></author-notes><pub-date pub-type="nihms-submitted"><day>18</day><month>7</month><year>2018</year></pub-date><pub-date pub-type="epub"><day>02</day><month>3</month><year>2018</year></pub-date><pub-date pub-type="ppub"><month>4</month><year>2018</year></pub-date><pub-date pub-type="pmc-release"><day>16</day><month>8</month><year>2018</year></pub-date><volume>49</volume><fpage>123</fpage><lpage>131</lpage><!--elocation-id from pubmed: 10.1016/j.conb.2018.02.005--><permissions><license><license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>).</license-p></license></permissions><abstract id="ABS1"><p id="P1">Phasic dopamine responses demonstrate remarkable simplicity; they code for the differences between received and predicted reward values. Yet this simplicity belies the subtle complexity of the psychological, computational, and contextual factors that influence this signal. Advances in behavioral paradigms and models, in monkeys and rodents, have demonstrated that phasic dopamine responses reflect numerous behavioral computations and factors including choice, subjective value, confidence, and context. The application of optogenetics has provided evidence that dopamine reward prediction error responses cause value learning. Furthermore, studies using advanced circuit tracing techniques have begun to uncover the biological network implementation of the reward learning algorithm. The purpose of this review is to summarize the recent advances in dopamine neurophysiology and synthesize an updated account of the behavioral function of dopamine signals.</p></abstract></article-meta></front><body><sec id="S1"><title>Introduction</title><p id="P2">Reward prediction errors are arguably one of the oldest biological computations on Earth. The single cell bacteria that dominated life for over two billion years detected and responded to positive and negative differences, in time and space, in the concentrations of environmental substances [<xref rid="R1" ref-type="bibr">1</xref>]. Positive concentration changes evoke approach behavior in the form of movements towards the source, whereas increasing concentrations of harmful chemicals cause bacteria to avoid the source and &#x02018;tumble&#x02019; away in random directions [<xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R3" ref-type="bibr">3</xref>]. Much has changed in two billion (or so) years of evolution, but computation of unpredicted changes for better or worse remains critical to optimal behavioral function and is broadly employed in the brain. Phasic dopamine responses constitute the prime example of neuronal reward prediction error coding.</p><p id="P3">Dopamine neurons are predominantly located in the midbrain A8, A9, and A10 cell groups that correspond roughly to the Retrorubral Field (RRF), the <italic>Substantia Nigra pars compacta</italic> (SNc) and Ventral Tegmental Area (VTA), respectively [<xref rid="R4" ref-type="bibr">4</xref>]. These neurons receive synaptic input from over 30 different brain regions [<xref rid="R5" ref-type="bibr">5</xref>&#x02013;<xref rid="R11" ref-type="bibr">11</xref>], and send the majority of their projections to basal ganglia and frontal cortex areas involved in motor control, learning, and cognitive function [<xref rid="R11" ref-type="bibr">11</xref>&#x02013;<xref rid="R14" ref-type="bibr">14</xref>]. They respond to rewards and reward predicting cues with phasic bursts of action potentials that code for reward prediction errors, the differences between received and predicted rewards [<xref rid="R15" ref-type="bibr">15</xref>,<xref rid="R16" ref-type="bibr">16<sup>&#x02022;</sup></xref>]. Dopamine prediction error responses are an ideal mechanism to guide behaviors to harvest more and better rewards. Positive prediction error responses indicate that the preceding action should be repeated or invigorated, whereas negative prediction error responses indicate that the preceding behavior should be decreased or avoided [<xref rid="R17" ref-type="bibr">17</xref>].</p><p id="P4">Recent studies have shown that numerous behavioral computations, including value, choice, confidence, and contextual expectations are factored into the canonical reward prediction error (RPE) response in dopamine neurons [<xref rid="R18" ref-type="bibr">18<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R19" ref-type="bibr">19</xref>&#x02013;<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R22" ref-type="bibr">22<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R23" ref-type="bibr">23</xref>]. Next generation technologies have been critical to understanding the behavioral functions of dopamine neurons [<xref rid="R24" ref-type="bibr">24<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R25" ref-type="bibr">25<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R27" ref-type="bibr">27</xref>,<xref rid="R28" ref-type="bibr">28</xref>], their downstream effects [<xref rid="R29" ref-type="bibr">29</xref>,<xref rid="R30" ref-type="bibr">30</xref>], and how they compute RPEs [<xref rid="R6" ref-type="bibr">6<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R9" ref-type="bibr">9</xref>,<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R33" ref-type="bibr">33</xref>,<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>]. This non-comprehensive review endeavors to highlight the recent novel findings in dopamine physiology as it pertains to reward coding and its behavioral consequences.</p></sec><sec id="S2"><title>Phasic dopamine signals are reinforcement learning signals</title><p id="P5">Prediction errors are the fundamental element of reinforcement learning models, including the Rescorla-Wagner [<xref rid="R35" ref-type="bibr">35</xref>] and temporal difference (TD) [<xref rid="R17" ref-type="bibr">17</xref>] models. Prediction errors are used to update (i.e., learn) the value of predictive stimuli. The prediction error in TD models provides a theoretical account for phasic dopamine activity [<xref rid="R36" ref-type="bibr">36</xref>,<xref rid="R37" ref-type="bibr">37</xref>]. The TD prediction error (TDPE) is a diference between the predicted and actual value:
<disp-formula id="FD1"><mml:math display="block" id="M1" overflow="scroll"><mml:mrow><mml:mtext>TDPE</mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>actual</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mtext>predicted</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p id="P6">Thus, subtraction is the fundamental operation that guides value updating. To verify that subtraction governs the response of dopamine neurons, the activity of optogenetically identified mouse dopamine neurons was recorded during reward delivery. The delivered rewards were either (a) completely unpredicted &#x02014; neither the magnitude nor timing was known, or (b) followed a cue (odor) that predicted the average magnitude and exact timing &#x02014; the prediction was a constant and only the exact reward magnitude was unknown. The constant reward expectation generated by the predictive odor reduced, by an equivalent amount, the dopamine response to every reward magnitude [<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>]. This result indicates that dopamine neurons perform subtraction of expected reward value from actual value, as opposed to using divisive operations that are more commonly observed in neural circuits [<xref rid="R38" ref-type="bibr">38</xref>,<xref rid="R39" ref-type="bibr">39</xref>]. Moreover, every recorded dopamine neuron used a similar subtractive algorithm [<xref rid="R31" ref-type="bibr">31</xref>]. These results confirm that, just like the prediction error signal that forms the core of reinforcement learning models, the magnitude of the phasic dopamine response is governed by subtraction.</p><p id="P7">More than two decades of research has provided strong correlational evidence that phasic dopamine responses constitute a reward learning signal (for a concise summary, see [<xref rid="R16" ref-type="bibr">16<sup>&#x02022;</sup></xref>], a more comprehensive review is provided in [<xref rid="R15" ref-type="bibr">15</xref>]). However, new techniques like optogenetics finally permit us to ask whether dopamine signals <italic>cause</italic> learning to occur. Prediction error responses have been simulated using optogenetic techniques in a variety of behavioral tasks in mice [<xref rid="R27" ref-type="bibr">27</xref>,<xref rid="R28" ref-type="bibr">28</xref>,<xref rid="R40" ref-type="bibr">40</xref>], rats [<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R41" ref-type="bibr">41</xref>,<xref rid="R42" ref-type="bibr">42</xref>], and monkeys [<xref rid="R25" ref-type="bibr">25<sup>&#x02022;&#x02022;</sup></xref>]. In every species tested, phasic optogenetic stimulation or suppression of dopamine neurons has resulted in behavioral obser-vations consistent with a critical role for dopamine neurons in reward learning.</p><p id="P8">A fundamental insight from animal learning theory is that rewards must be unpredicted, that is, they must generate reward prediction errors, for learning to occur [<xref rid="R35" ref-type="bibr">35</xref>]. The strongest evidence for the causal role of dopamine in learning comes from experimental manipulations in behavioral paradigms where prediction errors would not normally occur, and where no learning would normally happen. These paradigms reveal how introduction of phasic activations or suppressions of dopamine neurons affect learning. Effects of optical activation and suppression of dopamine neurons in rats have been tested during a blocking and an overestimation paradigm, respectively [<xref rid="R24" ref-type="bibr">24<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>].</p><p id="P9">During blocking, formation of associative strength between a conditioned stimulus (CS) and an unconditioned stimulus (US) is &#x02018;blocked&#x02019; by a secondary stimulus that fully predicts the US. Dopamine neurons do not respond to CSs that have been blocked [<xref rid="R43" ref-type="bibr">43</xref>]. Artificial phasic dopamine activations unblock the CS leading to increased conditioned responses (time spent in the reward port) and indicating learning of the unblocked CS-US association [<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>]. Thus, optogenetic activation of phasic dopamine mimics the effects of positive prediction errors, and is sufficient to cause associative learning. During overexpectation, the compound presentation of two reward-predicting CSs generates heightened expectation &#x02014; &#x02018;overexpectation&#x02019; &#x02014; that likely corresponds to both rewards being delivered. The negative prediction errors associated with delivery of only one reward leads to extinction of the original CS-reward associations [<xref rid="R35" ref-type="bibr">35</xref>,<xref rid="R44" ref-type="bibr">44</xref>&#x02013;<xref rid="R46" ref-type="bibr">46</xref>]. In a modified overexpectation paradigm, the two rewards were actually delivered, fulfilling the heightened expectations, and this modification eliminated the extinction. Phasic optogenetic silencing of dopamine neurons reinstates extinction learning in the modified overexpectation task [<xref rid="R24" ref-type="bibr">24<sup>&#x02022;&#x02022;</sup></xref>]. Thus, optogenetic silencing of dopamine mimics the effects of negative prediction errors, and is sufficient to cause extinction learning. Together, these findings provide evidence that phasic dopamine activations and suppressions constitute bidirectional teaching signals that cause increases and decreases (respectively) in the associative strengths between rewards and their predictors.</p><p id="P10">In many situations, including the behavioral tasks reviewed so far, dopamine signals update predictions using a &#x02018;model-free&#x02019;-like algorithm. That is, cue-outcome associations are updated according to direct experience of the cues and outcomes. In contrast, some outcomes can be used to update a model that contains multiple associations. Such &#x02018;model-based&#x02019; learning can occur, for instance, during a reversal learning task (for a review of model-free vs model-based reinforcement learning, see [<xref rid="R47" ref-type="bibr">47</xref>]). Monkeys learned that one cue predicted reward while another cue predicted no reward, and on a randomly selected trial the reward contingencies reversed. Model-based learning can use the outcome of the first reversal trial to update the value of both stimuli, even with no direct experience of the other cue-outcome association. Dopamine responses reflected values updated according to this model-based rule [<xref rid="R48" ref-type="bibr">48</xref>]. This result suggests that the dopamine system is adapted to efficiently learn environmental reward contingencies whether they are experienced directly or merely inferred. Accordingly, this neuronal teaching signal can support multiple forms of reinforcement learning and likely updates value correlates throughout the brain.</p></sec><sec id="S3"><title>Dopamine responses reflect behavioral computations associated with value</title><p id="P11">Most rewards do not possess a common physical scale for direct comparison, and they often enter awareness via biophysically distinct pathways. Food, drink, money, and social interaction are but a few examples of the larger category of objects, events, or thoughts that we readily recognize as rewards [<xref rid="R15" ref-type="bibr">15</xref>]. Despite the heterogeneity of reward features, individuals quickly appreciate reward value and readily exchange one reward for another. For example, individuals readily handover money in exchange for ice cream. This behavior implies that coding of reward value is not critically dependent of the sensory properties of rewards. When monkeys make choices between different reward types, dopamine responses are larger to more preferred rewards, compared to less preferred rewards. Importantly, when choices indicate indifference between two rewards, the dopamine responses to those rewards are indistinguishable (<xref rid="F1" ref-type="fig">Figure 1a</xref>) [<xref rid="R20" ref-type="bibr">20</xref>]. Similarly, when rats have been fed to satiety on one reward, their choices indicate that value of the overfed reward is decreased, and the dopamine response to the overfed reward is also decreased [<xref rid="R49" ref-type="bibr">49</xref>]. These patterns of activity suggest that dopamine responses reflect the subjective value of rewards.</p><p id="P12">To demonstrate the functional relationship between subjective value and dopamine activity, subjective value was measured as a function of physical value in monkeys making choices between risky and safe outcomes. There is a mathematical relationship between risk attitudes, whether the monkey is risk seeking or risk avoiding, and the curvatures of the resulting value functions [<xref rid="R50" ref-type="bibr">50</xref>]. Choices between risky rewards revealed an &#x02018;S&#x02019;-shaped subjective value (utility) function that reflected risk seeking for small rewards and risk avoiding for large rewards (<xref rid="F1" ref-type="fig">Figure 1b</xref>, red line) [<xref rid="R23" ref-type="bibr">23</xref>,<xref rid="R51" ref-type="bibr">51</xref>]. The magnitudes of dopamine responses to unpredicted rewards were correlated with the shape of the measured utility functions (<xref rid="F1" ref-type="fig">Figure 1b</xref>) [<xref rid="R23" ref-type="bibr">23</xref>]. During behavioral choices, dopamine responses scaled with the value of the chosen options [<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R52" ref-type="bibr">52</xref>]. Moreover, dopamine responses were larger on trials when the monkey indicated the correct choice, compared to when it was mistaken (<xref rid="F1" ref-type="fig">Figure 1c</xref>) [<xref rid="R19" ref-type="bibr">19</xref>]. These results demonstrate that dopamine responses integrate moment-by-moment behavioral information with reinforcement learning to code the same dynamic value information that is used to make decisions.</p><p id="P13">Value may be gained from physical rewards, but also may be derived from the internal evaluation of performance. A novel study examined dopamine activity during bird song learning. As juvenile birds learned to sing, distorted audio feedback (DAF) was provided at unpredictable times. Dopamine neurons paused their firing when they heard the DAF, as though they were responding to a negative prediction error (<xref rid="F1" ref-type="fig">Figure 1d</xref>). The response was contingent upon the bird singing; dopamine neurons were unaffected by DAF when they were not singing [<xref rid="R18" ref-type="bibr">18<sup>&#x02022;&#x02022;</sup></xref>]. This result demonstrates that dopamine neurons are active during performance monitoring, but it remains unclear whether this response reflected the performance error itself or whether it reflected the value of that error. Developing behavioral technologies to measure the value of good performance is key to understanding how reward and motor systems interact to motivate motor learning.</p><p id="P14">Value has many sources, including long term reinforcement learning history, context, and trial-by-trial behavioral factors. Overall, these recent studies demonstrate that dopamine prediction error responses reflect these many sources of value, and provide deeper insights into the nature of biological reinforcement learning.</p></sec><sec id="S4"><title>Biological implementation of reward prediction error computations</title><p id="P15">Dopamine neurons receive input from more than thirty brain areas, including the lateral hypothalamus, subthalamic nucleus, the pedunculopontine nucleus, the lateral habenula, the striatum, and the dorsal raphe nucleus [<xref rid="R6" ref-type="bibr">6<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R53" ref-type="bibr">53</xref>,<xref rid="R54" ref-type="bibr">54</xref>]. It is of considerable interest how dopamine neurons integrate information from these diverse brain regions to compute RPE.</p><p id="P16">Electrophysiological analysis of more than 200 neurons mono-synaptically connected to VTA dopamine neurons revealed that most input neurons coded for some computational components of RPEs, such as responses to unpredicted rewards or reward expectation. These different component responses were not localized to specific input nuclei, but rather were distributed across all the sampled nuclei [<xref rid="R6" ref-type="bibr">6<sup>&#x02022;&#x02022;</sup></xref>]. Thus, dopamine neurons receive distributed inputs from many structures in the brain that code for parts of the RPE, and appear to integrate these distributed inputs to compute RPE responses.</p><p id="P17">A critical factor determining the dopamine response is the cell type-identity of their inputs. For example, the lateral hypothalamus (LH) is a major source of input to the midbrain. Optogenetic activations of GABAergic projections from the LH to the VTA cause phasic dopamine release in the striatum and promote reward seeking behaviors [<xref rid="R9" ref-type="bibr">9</xref>,<xref rid="R33" ref-type="bibr">33</xref>]. By contrast, phasic activations of LH glutamatergic projections to the midbrain result in avoidance behaviors [<xref rid="R9" ref-type="bibr">9</xref>]. The appetitive and aversive effects of LH inputs seem to operate through di-synaptic mechanisms involving local GABA neurons in the vicinity of the VTA [<xref rid="R9" ref-type="bibr">9</xref>]. However, the exact identity and location of GABA neurons mediating the disinhibition that could lead to dopamine activations remains unclear. Although LH-GABA neurons synapse onto GABAergic neurons in the VTA [<xref rid="R9" ref-type="bibr">9</xref>], previous research has failed to find consistent, phasic inhibition of VTA-GABA neurons at the precise moments when such inhibitions could mediate dopamine activations [<xref rid="R55" ref-type="bibr">55</xref>].</p><p id="P18">Similar to the input from the LH, the different cell types in the dorsal raphe nucleus (DRN) differentially contribute to appetitive and aversive dopamine-mediated behaviors. Both serotonergic and glutamatergic projections from the DRN appear to provide appetitive information to dopamine neurons [<xref rid="R53" ref-type="bibr">53</xref>&#x02013;<xref rid="R56" ref-type="bibr">56</xref>], whereas DRN GABA neuron activity is correlated with aversive responses [<xref rid="R56" ref-type="bibr">56</xref>].</p><p id="P19">Glutamatergic projection neurons in the lateral habenula (LHb) are a major source of aversive information to dopamine neurons. Activation of LHb inhibits the majority of dopamine neurons via di-synaptic connections with GABAergic neurons in the rostromedial tegmental nucleus (RMTg) [<xref rid="R57" ref-type="bibr">57</xref>&#x02013;<xref rid="R59" ref-type="bibr">59</xref>]. Activation of this pathway causes conditioned place aversion [<xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R60" ref-type="bibr">60</xref>], whereas lesioning this pathway disrupts the normal inhibitory responses to unpredicted reward omission [<xref rid="R8" ref-type="bibr">8<sup>&#x02022;&#x02022;</sup></xref>]. Thus, the majority of LHb activation is related to negative prediction error responses (pauses) in dopamine neurons. Studies in the mouse have recently discovered a group of dopamine neurons that receive mono-synaptic, excitatory drive from the LHb [<xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R61" ref-type="bibr">61</xref>]. Notably, this group of dopamine neurons has different electrophysiological properties than dopamine neurons that have been identified with apomorphine [<xref rid="R62" ref-type="bibr">62</xref>&#x02013;<xref rid="R65" ref-type="bibr">65</xref>] and optogenetics [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R55" ref-type="bibr">55</xref>]. They emit action potentials at much higher rates than classical dopamine neurons, and do not express somatodendritic dopamine D2 receptors [<xref rid="R61" ref-type="bibr">61</xref>]. As such, they are likely insensitive to apomorphine. Because of the distinct electrophysiological properties and putative apomorphine insensitivity, these neurons are not likely to be sampled by studies that use traditional waveform identification techniques [<xref rid="R62" ref-type="bibr">62</xref>&#x02013;<xref rid="R65" ref-type="bibr">65</xref>]. Therefore, it remains to be seen what the behavioral function of these neurons is, and indeed whether they code for prediction errors.</p></sec><sec id="S5"><title>Diversity of dopamine responses</title><p id="P20">The majority of dopamine neurons are activated by reward [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R55" ref-type="bibr">55</xref>,<xref rid="R66" ref-type="bibr">66</xref>]. However, dopamine neurons do not respond solely to rewards, nor do all dopamine neurons respond identically. In fact, numerous other stimuli elicit dopamine responses, including noxious, aversive, and physically salient stimuli [<xref rid="R64" ref-type="bibr">64</xref>,<xref rid="R67" ref-type="bibr">67</xref>&#x02013;<xref rid="R73" ref-type="bibr">73</xref>], novelty [<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R73" ref-type="bibr">73</xref>], and large movements [<xref rid="R74" ref-type="bibr">74</xref>,<xref rid="R75" ref-type="bibr">75</xref>]. Likewise, the well-known role of dopamine neuron loss in movement disorders and Parkinson&#x02019;s disease clearly implicates these neurons in movement, albeit indirectly. These observations have generated intense interest into the functional heterogeneity of the dopamine population.</p><p id="P21">Phasic dopamine responses display complex temporal dynamics that may reflect different variables and even have multiple behavioral functions [<xref rid="R19" ref-type="bibr">19</xref>,<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R70" ref-type="bibr">70</xref>,<xref rid="R71" ref-type="bibr">71</xref>,<xref rid="R76" ref-type="bibr">76</xref>]. Dopamine neurons generally encode RPEs at latencies between 150 and 250 ms following reward; the longer latencies are observed when stimuli are hard to distinguish or the experiment highly dynamic [<xref rid="R19" ref-type="bibr">19</xref>,<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R77" ref-type="bibr">77</xref>]. On the other hand, many non-reward activations of dopamine neurons occur very early in the response, within 50&#x02013;200 ms of the behavioral event. Aversive air-puffs evoke short-latency activations and inhibitions in dorsolateral and ventromedial dopamine neurons, respectively [<xref rid="R72" ref-type="bibr">72</xref>]. Similarly, aversive electrical shocks activate dopamine neurons projecting to the dorsolateral striatum (DLS), whereas the same stimuli inhibit dopamine neurons projecting to the dorsomedial striatum (DMS) [<xref rid="R68" ref-type="bibr">68</xref>]. The Ca<sup>2+</sup> signal used to detect the electric shock activations and inhibitions has a slower time-course than action potential signals [<xref rid="R78" ref-type="bibr">78</xref>]. Nevertheless, in dopamine neurons that project to the DLS, activations driven by electric shock appear faster and shorter than activations driven by reward [<xref rid="R68" ref-type="bibr">68</xref>]. Thus, dopamine responses to aversive stimuli are heterogeneous, but short-latency non-reward responses appear to arise earlier than RPE coding.</p><p id="P22">Context sensitivity also plays an important role in dopamine response heterogeneity. Context can be defined by numerous factors including the overall reward availability, task dynamics, and the physical nature of stimuli and rewards. In particular, the overall reward availability strongly modulates dopamine responses to rewards, reward predictors, and nonrewards. For example, when the overall availability of rewards was low (i.e., rewards were only delivered on a small fraction of trials) dopamine neurons responded to aversive stimuli with inhibitions. However, when the overall availability of rewards was high, the very same dopamine neuron respond to aversive stimuli with short-latency activations, rather than inhibitions [<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>]. Neutral cues were similarly influenced by the amount of reward delivered in a specific context; greater overall reward availability resulted in greater responses to neutral cues [<xref rid="R79" ref-type="bibr">79</xref>]. Because of the influence of overall reward availability, the short-latency activations observed in these (and other) studies are likely instances of pseudo-conditioning, a process of generalization between USs, rather than true responses to nonrewarding stimuli [<xref rid="R80" ref-type="bibr">80</xref>]. In a similar fashion, sensory stimulus (CS) generalization has a major impact on the number of dopamine neurons that respond to aversive-predicting CS. When visual cues are used to predict both rewarding and aversive outcomes, more than half of dopamine neurons can respond to the aversive visual cue [<xref rid="R66" ref-type="bibr">66</xref>,<xref rid="R72" ref-type="bibr">72</xref>]. This is in contrast to when an auditory cue is used to predict a reward and a visual cue is used to predict an aversive air puff, only 15% of dopamine neurons respond to the aversive visual cue [<xref rid="R66" ref-type="bibr">66</xref>]. Thus, less stimulus generalization translates into fewer dopamine neurons responding to aversive events. These critical studies highlight the importance of considering behavioral and contextual factors, in addition to the underlying circuits, when designing behavioral tasks and interpreting the motivational implications of dopamine activity.</p></sec><sec id="S6"><title>Conclusions</title><p id="P23">The value assigned to rewards is a highly dynamic quantity influenced by numerous factors. Dopamine responses code for subjective reward value (utility) [<xref rid="R20" ref-type="bibr">20</xref>,<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R23" ref-type="bibr">23</xref>] and reflect the numerous behavioral factors that influence value, including choice [<xref rid="R21" ref-type="bibr">21</xref>,<xref rid="R81" ref-type="bibr">81</xref>], confidence [<xref rid="R19" ref-type="bibr">19</xref>], context [<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R79" ref-type="bibr">79</xref>], and satiety [<xref rid="R49" ref-type="bibr">49</xref>]. Optogenetic stimulation and suppression of dopamine neurons demonstrates that these signals cause value learning [<xref rid="R24" ref-type="bibr">24<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>], which likely updates action values in the striatum and elsewhere [<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R82" ref-type="bibr">82</xref>&#x02013;<xref rid="R84" ref-type="bibr">84</xref>]. Beyond learning, dopamine neurons have many behavioral functions including roles in movement and motivation. Not discussed here, but at the cutting edge of dopamine investigations, are studies deciphering the precise behavioral roles of prediction error coding and dopamine release at the interface between motivation and movement [<xref rid="R29" ref-type="bibr">29</xref>,<xref rid="R30" ref-type="bibr">30</xref>].</p><p id="P24">Our current understanding of dopamine neurons has been greatly facilitated by recent technological developments, including optogenetics and advanced circuit tracing techniques. Optogenetic technologies have been used to unambiguously identify dopamine neurons and test their behavioral function [<xref rid="R6" ref-type="bibr">6<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R22" ref-type="bibr">22<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R55" ref-type="bibr">55</xref>]. These studies have confirmed the major role that dopamine neurons have in reward coding [<xref rid="R55" ref-type="bibr">55</xref>], and detailed the algorithm used by the dopamine population [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>]. Optogenetics stimulation has been used to test and confirm the hypothesis that phasic dopamine activations and suppressions constitute a bi-directional teaching signal for value learning [<xref rid="R24" ref-type="bibr">24<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R26" ref-type="bibr">26<sup>&#x02022;&#x02022;</sup></xref>]. Optogenetic stimulation of monkey dopamine neurons biases the choices of the animal to the stimulation-reinforced options, and translates these technological capabilities into a species with greater anatomical and functional homology with humans [<xref rid="R25" ref-type="bibr">25<sup>&#x02022;&#x02022;</sup></xref>].</p><p id="P25">In the physical dopamine circuit, perhaps more than anywhere else in the brain, we are starting to understand the Marr-level III implementation of the reward prediction error algorithm [<xref rid="R85" ref-type="bibr">85</xref>]. Recent studies have mapped the anatomical and functional inputs of dopamine neurons [<xref rid="R6" ref-type="bibr">6<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R8" ref-type="bibr">8<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R9" ref-type="bibr">9</xref>,<xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R33" ref-type="bibr">33</xref>,<xref rid="R34" ref-type="bibr">34<sup>&#x02022;&#x02022;</sup></xref>,<xref rid="R61" ref-type="bibr">61</xref>]. These results demonstrate how different cell types and the micro-circuits they form are critical to understand how dopamine responses are shaped. An important question for future studies to address is, &#x02018;what level of circuit detail is relevant to behavioral function?&#x02019; Advancing technological capabilities are revealing ever more complex circuit maps with ever finer details, but it is critical that these findings are interpreted in light of well-founded behavioral theories and experiments [<xref rid="R86" ref-type="bibr">86</xref>]. Nevertheless, these developments promise to provide deeper insights into the behavioral functions and information processing capacities of this critical neural system.</p><p id="P26">The next step, I believe, is to gain a broader and clearer appreciation of the nature of reward predictions. To say that dopamine neurons code for reward prediction errors is to imply subtraction is taking place. The operation of subtraction includes three terms, the minuend (the number being subtracted from), the subtrahend (the number being subtracted), and the resulting difference. Recent studies have confirmed that dopamine prediction error responses truly represent differences [<xref rid="R31" ref-type="bibr">31</xref>,<xref rid="R32" ref-type="bibr">32<sup>&#x02022;&#x02022;</sup></xref>]. Therefore, to fully understand the dopamine signal, we need to understand how dopamine neurons code the minuend (reward) and the subtrahend (prediction). Regarding the former, significant progress has been made in understanding how the brain codes for rewards. Signals related to subjective value have been recorded in multiple brain areas. Dopamine neurons reflect multiple attributes of reward, including reward magnitude [<xref rid="R87" ref-type="bibr">87</xref>], probability [<xref rid="R88" ref-type="bibr">88</xref>,<xref rid="R89" ref-type="bibr">89</xref>], and delay [<xref rid="R90" ref-type="bibr">90</xref>]. They integrate these attributes and code for a highly specified form of subjective reward value, economic utility, that places the value of different rewards on a common scale for easy comparison [<xref rid="R20" ref-type="bibr">20</xref>,<xref rid="R23" ref-type="bibr">23</xref>]. Well-defined and easily measured utility functions, therefore, provide a rigorous account of the dopaminergic minuend (<xref rid="F1" ref-type="fig">Figure 1b</xref>). However, we know less about the dopaminergic subtrahend: reward predictions. The classical model for dopamine activity, the TD model, predicts the time-discounted expected value of future rewards [<xref rid="R36" ref-type="bibr">36</xref>]. Although this quantity is surely factored into dopamine signals, the results reviewed here demonstrate that this model provides an inadequate description of dopamine activity. Inference about hidden states of the world as well as factors related to decision confidence are incorporated into dopamine responses [<xref rid="R19" ref-type="bibr">19</xref>,<xref rid="R22" ref-type="bibr">22<sup>&#x02022;&#x02022;</sup></xref>]; both of these factors are well beyond simple first-order reward statistics. These results indicate that the reward predictions made by dopamine neurons, and by implication the brain, are far richer than was previously thought. Fortunately, the well-defined nature of the dopamine signal provides an excellent substrate to learn about the shape and character of neuronal predictions.</p></sec></body><back><ack id="S7"><title>Acknowledgements</title><p id="P27">This work was funded by the University of Pittsburgh Brain Institute and by the National Institutes of Health through the NIH Director&#x02019;s New Innovator Award 1DP2MH113095.</p></ack><fn-group><fn fn-type="COI-statement" id="FN1"><p id="P28">Conflict of interest statement</p><p id="P29">Nothing declared.</p></fn></fn-group><ref-list><title>References and recommended reading</title><p id="P30">Papers of particular interest, published within the period of review, have been highlighted as:</p><p id="P31">&#x02022; of special interest</p><p id="P32">&#x02022;&#x02022; of outstanding interest</p><ref id="R1"><label>1.</label><mixed-citation publication-type="journal"><name><surname>Segall</surname><given-names>JE</given-names></name>, <name><surname>Block</surname><given-names>SM</given-names></name>, <name><surname>Berg</surname><given-names>HC</given-names></name>: <article-title>Temporal comparisons in bacterial chemotaxis</article-title>. <source>Proc Natl Acad Sci USA</source>
<year>1986</year>, <volume>83</volume>:<fpage>8987</fpage>&#x02013;<lpage>8991</lpage>.<pub-id pub-id-type="pmid">3024160</pub-id></mixed-citation></ref><ref id="R2"><label>2.</label><mixed-citation publication-type="journal"><name><surname>Macnab</surname><given-names>RM</given-names></name>, <name><surname>Koshland</surname><given-names>DE</given-names><suffix>Jr</suffix></name>: <article-title>The gradient-sensing mechanism in bacterial chemotaxis</article-title>. <source>Proc Natl Acad Sci U S A</source>
<year>1972</year>, <volume>69</volume>:<fpage>2509</fpage>&#x02013;<lpage>2512</lpage>.<pub-id pub-id-type="pmid">4560688</pub-id></mixed-citation></ref><ref id="R3"><label>3.</label><mixed-citation publication-type="journal"><name><surname>Adler</surname><given-names>J</given-names></name>: <article-title>Chemotaxis in bacteria</article-title>. <source>Annu Rev Biochem</source>
<year>1975</year>, <volume>44</volume>:<fpage>341</fpage>&#x02013;<lpage>356</lpage>.<pub-id pub-id-type="pmid">1094913</pub-id></mixed-citation></ref><ref id="R4"><label>4.</label><mixed-citation publication-type="journal"><name><surname>Dahlstroem</surname><given-names>A</given-names></name>, <name><surname>Fuxe</surname><given-names>K</given-names></name>: <article-title>Evidence for the existence of monoamine-containing neurons in the central nervous system. I. Demonstration of monoamines in the cell bodies of brain stem neurons</article-title>. <source>Acta Physiol Scand Suppl</source>
<year>1964</year>, <issue>Suppl. 232</issue>:<fpage>231</fpage>&#x02013;<lpage>255</lpage>.</mixed-citation></ref><ref id="R5"><label>5.</label><mixed-citation publication-type="journal"><name><surname>Dautan</surname><given-names>D</given-names></name>, <name><surname>Souza</surname><given-names>AS</given-names></name>, <name><surname>Huerta-Ocampo</surname><given-names>I</given-names></name>, <name><surname>Valencia</surname><given-names>M</given-names></name>, <name><surname>Assous</surname><given-names>M</given-names></name>, <name><surname>Witten</surname><given-names>IB</given-names></name>, <name><surname>Deisseroth</surname><given-names>K</given-names></name>, <name><surname>Tepper</surname><given-names>JM</given-names></name>, <name><surname>Bolam</surname><given-names>JP</given-names></name>, <name><surname>Gerdjikov</surname><given-names>TV</given-names></name>
<etal/>:<article-title>Segregated cholinergic transmission modulates dopamine neurons integrated in distinct functional circuits</article-title>. <source>Nat Neurosci</source>
<year>2016</year>, <volume>19</volume>:<fpage>1025</fpage>&#x02013;<lpage>1033</lpage>.<pub-id pub-id-type="pmid">27348215</pub-id></mixed-citation></ref><ref id="R6"><label>6.&#x02022;&#x02022;</label><note><p id="P33"><mixed-citation publication-type="journal" id="P33-gen-1"><name><surname>Tian</surname><given-names>J</given-names></name>, <name><surname>Huang</surname><given-names>R</given-names></name>, <name><surname>Cohen</surname><given-names>JY</given-names></name>, <name><surname>Osakada</surname><given-names>F</given-names></name>, <name><surname>Kobak</surname><given-names>D</given-names></name>, <name><surname>Machens</surname><given-names>CK</given-names></name>, <name><surname>Callaway</surname><given-names>EM</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>, <name><surname>Watabe-Uchida</surname><given-names>M</given-names></name>: <article-title>Distributed and mixed information in monosynaptic inputs to dopamine neurons</article-title>. <source>Neuron</source>
<year>2016</year>, <volume>91</volume>:<fpage>1374</fpage>&#x02013;<lpage>1389</lpage>.<pub-id pub-id-type="pmid">27618675</pub-id></mixed-citation></p><p id="P34">A modified rabies virus infected neurons mono-synaptically connected to dopamine neurons (&#x02018;input neurons&#x02019;) and caused the input neurons to express ChR2. The authors used optical stimulation to identify input neurons during behavior. Information that dopamine neurons use to compute RPE was distributed across many brain areas. Dopamine responses could be reconstructed from the input.</p></note></ref><ref id="R7"><label>7.</label><mixed-citation publication-type="journal"><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name>, <name><surname>Zhu</surname><given-names>L</given-names></name>, <name><surname>Ogawa</surname><given-names>SK</given-names></name>, <name><surname>Vamanrao</surname><given-names>A</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>:<article-title>Whole-brain mapping of direct inputs to midbrain dopamine neurons</article-title>. <source>Neuron</source>
<year>2012</year>, <volume>74</volume>:<fpage>858</fpage>&#x02013;<lpage>873</lpage>.<pub-id pub-id-type="pmid">22681690</pub-id></mixed-citation></ref><ref id="R8"><label>8.&#x02022;&#x02022;</label><note><p id="P35"><mixed-citation publication-type="journal" id="P35-gen-1"><name><surname>Tian</surname><given-names>J</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>: <article-title>Habenula lesions reveal that multiple mechanisms underlie dopamine prediction errors</article-title>. <source>Neuron</source>
<year>2015</year>, <volume>87</volume>:<fpage>1304</fpage>&#x02013;<lpage>1316</lpage>.<pub-id pub-id-type="pmid">26365765</pub-id></mixed-citation></p><p id="P36">Habenula lesions in mice disrupted the pause in action potentials that dopamine neurons exhibit to unpredicted reward omissions. The same lesions left the rest of the RPE response, including pauses to aversive stimuli, intact. This result provides evidence that dopamine neurons compute the RPE using distributed inputs.</p></note></ref><ref id="R9"><label>9.</label><mixed-citation publication-type="journal"><name><surname>Nieh</surname><given-names>EH</given-names></name>, <name><surname>Vander Weele</surname><given-names>CM</given-names></name>, <name><surname>Matthews</surname><given-names>GA</given-names></name>, <name><surname>Presbrey</surname><given-names>KN</given-names></name>, <name><surname>Wichmann</surname><given-names>R</given-names></name>, <name><surname>Leppla</surname><given-names>CA</given-names></name>, <name><surname>Izadmehr</surname><given-names>EM</given-names></name>, <name><surname>Tye</surname><given-names>KM</given-names></name>: <article-title>Inhibitory input from the lateral hypothalamus to the ventral tegmental area disinhibits dopamine neurons and promotes behavioral activation</article-title>. <source>Neuron</source>
<year>2016</year>, <volume>90</volume>:<fpage>1286</fpage>&#x02013;<lpage>1298</lpage>.<pub-id pub-id-type="pmid">27238864</pub-id></mixed-citation></ref><ref id="R10"><label>10.</label><mixed-citation publication-type="journal"><name><surname>Lammel</surname><given-names>S</given-names></name>, <name><surname>Lim</surname><given-names>BK</given-names></name>, <name><surname>Ran</surname><given-names>C</given-names></name>, <name><surname>Huang</surname><given-names>KW</given-names></name>, <name><surname>Betley</surname><given-names>MJ</given-names></name>, <name><surname>Tye</surname><given-names>KM</given-names></name>, <name><surname>Deisseroth</surname><given-names>K</given-names></name>, <name><surname>Malenka</surname><given-names>RC</given-names></name>: <article-title>Input-specific control of reward and aversion in the ventral tegmental area</article-title>. <source>Nature</source>
<year>2012</year>, <volume>491</volume>:<fpage>212</fpage>&#x02013;<lpage>217</lpage>.<pub-id pub-id-type="pmid">23064228</pub-id></mixed-citation></ref><ref id="R11"><label>11</label><mixed-citation publication-type="journal"><name><surname>Beier</surname><given-names>KT</given-names></name>, <name><surname>Steinberg</surname><given-names>EE</given-names></name>, <name><surname>DeLoach</surname><given-names>KE</given-names></name>, <name><surname>Xie</surname><given-names>S</given-names></name>, <name><surname>Miyamichi</surname><given-names>K</given-names></name>, <name><surname>Schwarz</surname><given-names>L</given-names></name>, <name><surname>Gao</surname><given-names>XJ</given-names></name>, <name><surname>Kremer</surname><given-names>EJ</given-names></name>, <name><surname>Malenka</surname><given-names>RC</given-names></name>, <name><surname>Luo</surname><given-names>L</given-names></name>: <article-title>Circuit architecture of VTA dopamine neurons revealed by systematic input-output mapping</article-title>. <source>Cell</source>
<year>2015</year>, <volume>162</volume>:<fpage>622</fpage>&#x02013;<lpage>634</lpage>.<pub-id pub-id-type="pmid">26232228</pub-id></mixed-citation></ref><ref id="R12"><label>12</label><mixed-citation publication-type="journal"><name><surname>Lynd-Balta</surname><given-names>E</given-names></name>, <name><surname>Haber</surname><given-names>SN</given-names></name>: <article-title>The organization of midbrain projections to the ventral striatum in the primate</article-title>. <source>Neuroscience</source>
<year>1994</year>, <volume>59</volume>:<fpage>609</fpage>&#x02013;<lpage>623</lpage>.<pub-id pub-id-type="pmid">7516505</pub-id></mixed-citation></ref><ref id="R13"><label>13.</label><mixed-citation publication-type="journal"><name><surname>Lynd-Balta</surname><given-names>E</given-names></name>, <name><surname>Haber</surname><given-names>SN</given-names></name>: <article-title>The organization of midbrain projections to the striatum in the primate: sensorimotor-related striatum versus ventral striatum</article-title>. <source>Neuroscience</source>
<year>1994</year>, <volume>59</volume>:<fpage>625</fpage>&#x02013;<lpage>640</lpage>.<pub-id pub-id-type="pmid">7516506</pub-id></mixed-citation></ref><ref id="R14"><label>14</label><mixed-citation publication-type="journal"><name><surname>Lynd-Balta</surname><given-names>E</given-names></name>, <name><surname>Haber</surname><given-names>SN</given-names></name>: <article-title>Primate striatonigral projections: a comparison of the sensorimotor-related striatum and the ventral striatum</article-title>. <source>J Comp Neurol</source>
<year>1994</year>, <volume>345</volume>:<fpage>562</fpage>&#x02013;<lpage>578</lpage>.<pub-id pub-id-type="pmid">7962700</pub-id></mixed-citation></ref><ref id="R15"><label>15.</label><mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Neuronal reward and decision signals: from theories to data</article-title>. <source>Physiol Rev</source>
<year>2015</year>, <volume>95</volume>:<fpage>853</fpage>&#x02013;<lpage>951</lpage>.<pub-id pub-id-type="pmid">26109341</pub-id></mixed-citation></ref><ref id="R16"><label>16.&#x02022;</label><note><p id="P37"><mixed-citation publication-type="journal" id="P37-gen-1"><name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Reward prediction error</article-title>. <source>Curr Biol</source>
<year>2017</year>, <volume>27</volume>:<fpage>R369</fpage>&#x02013;<lpage>R371</lpage>.<pub-id pub-id-type="pmid">28535383</pub-id></mixed-citation></p><p id="P38">A simple and straightforward primer on reward prediction errors.</p></note></ref><ref id="R17"><label>17.</label><mixed-citation publication-type="book"><name><surname>Sutton</surname><given-names>R</given-names></name>, <name><surname>Barto</surname><given-names>A</given-names></name>: <source>Reinforcement Learning: An Introduction</source>. <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation></ref><ref id="R18"><label>18.&#x02022;&#x02022;</label><note><p id="P39"><mixed-citation publication-type="journal" id="P39-gen-1"><name><surname>Gadagkar</surname><given-names>V</given-names></name>, <name><surname>Puzerey</surname><given-names>PA</given-names></name>, <name><surname>Chen</surname><given-names>R</given-names></name>, <name><surname>Baird-Daniel</surname><given-names>E</given-names></name>, <name><surname>Farhang</surname><given-names>AR</given-names></name>, <name><surname>Goldberg</surname><given-names>JH</given-names></name>: <article-title>Dopamine neurons encode performance error in singing birds</article-title>. <source>Science</source>
<year>2016</year>, <volume>354</volume>:<fpage>1278</fpage>&#x02013;<lpage>1282</lpage>.<pub-id pub-id-type="pmid">27940871</pub-id></mixed-citation></p><p id="P40">During song learning, finch dopamine neurons are inhibited by simulated mistakes in their singing. This result demonstrates that dopamine neurons are sensitive to performance, and could provide a link between dopamine activity and motor learning.</p></note></ref><ref id="R19"><label>19.</label><mixed-citation publication-type="journal"><name><surname>Lak</surname><given-names>A</given-names></name>, <name><surname>Nomoto</surname><given-names>K</given-names></name>, <name><surname>Keramati</surname><given-names>M</given-names></name>, <name><surname>Sakagami</surname><given-names>M</given-names></name>, <name><surname>Kepecs</surname><given-names>A</given-names></name>: <article-title>Midbrain dopamine neurons signal belief in choice accuracy during a perceptual decision</article-title>. <source>Curr Biol</source>
<year>2017</year>, <volume>27</volume>:<fpage>821</fpage>&#x02013;<lpage>832</lpage>.<pub-id pub-id-type="pmid">28285994</pub-id></mixed-citation></ref><ref id="R20"><label>20.</label><mixed-citation publication-type="journal"><name><surname>Lak</surname><given-names>A</given-names></name>, <name><surname>Stauffer</surname><given-names>WR</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Dopamine prediction error responses integrate subjective value from different reward dimensions</article-title>. <source>Proc Natl Acad Sci USA</source>
<year>2014</year>, <volume>111</volume>:<fpage>2343</fpage>&#x02013;<lpage>2348</lpage>.<pub-id pub-id-type="pmid">24453218</pub-id></mixed-citation></ref><ref id="R21"><label>21.</label><mixed-citation publication-type="journal"><name><surname>Lak</surname><given-names>A</given-names></name>, <name><surname>Stauffer</surname><given-names>WR</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Dopamine neurons learn relative chosen value from probabilistic rewards</article-title>. <source>Elife</source>
<year>2016</year>:<fpage>5</fpage>.</mixed-citation></ref><ref id="R22"><label>22.&#x02022;&#x02022;</label><note><p id="P41"><mixed-citation publication-type="journal" id="P41-gen-1"><name><surname>Starkweather</surname><given-names>CK</given-names></name>, <name><surname>Babayan</surname><given-names>BM</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>, <name><surname>Gershman</surname><given-names>SJ</given-names></name>: <article-title>Dopamine reward prediction errors reflect hidden-state inference across time</article-title>. <source>Nat Neurosci</source>
<year>2017</year>, <volume>20</volume>:<fpage>581</fpage>&#x02013;<lpage>589</lpage>.<pub-id pub-id-type="pmid">28263301</pub-id></mixed-citation></p><p id="P42">The exact timing of reward delivery was not predicted, and in 10% of trials, it was not delivered at all. Thus, as the trials progressed, there was greater subjective evidence that reward would never be delivered, and greater surprise inthe 90% of trials when it was. This temporally dynamic inference about whether the trial was rewarded or not was reflected in the dopamine response. This result demonstrates that dopamine RPE responses incorporate highly dynamic information, and provide deeper insights into the nature of the biological reinforcement learning algorithm.</p></note></ref><ref id="R23"><label>23.</label><mixed-citation publication-type="journal"><name><surname>Stauffer</surname><given-names>WR</given-names></name>, <name><surname>Lak</surname><given-names>A</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Dopamine reward prediction error responses reflect marginal utility</article-title>. <source>Curr Biol</source>
<year>2014</year>,<volume>24</volume>:<fpage>2491</fpage>&#x02013;<lpage>2500</lpage>.<pub-id pub-id-type="pmid">25283778</pub-id></mixed-citation></ref><ref id="R24"><label>24.&#x02022;&#x02022;</label><note><p id="P43"><mixed-citation publication-type="journal" id="P43-gen-1"><name><surname>Chang</surname><given-names>CY</given-names></name>, <name><surname>Esber</surname><given-names>GR</given-names></name>, <name><surname>Marrero-Garcia</surname><given-names>Y</given-names></name>, <name><surname>Yau</surname><given-names>HJ</given-names></name>, <name><surname>Bonci</surname><given-names>A</given-names></name>, <name><surname>Schoenbaum</surname><given-names>G</given-names></name>: <article-title>Brief optogenetic inhibition of dopamine neurons mimics endogenous negative reward prediction errors</article-title>. <source>Nat Neurosci</source>
<year>2016</year>, <volume>19</volume>:<fpage>111</fpage>&#x02013;<lpage>116</lpage>.<pub-id pub-id-type="pmid">26642092</pub-id></mixed-citation></p><p id="P44">Using an &#x02018;overexpectation&#x02019; paradigm, the authors show that phasic dopamine pauses &#x02014; negative prediction error responses &#x02014; are sufficient to cause extinction.</p></note></ref><ref id="R25"><label>25.&#x02022;&#x02022;</label><note><p id="P45"><mixed-citation publication-type="journal" id="P45-gen-1"><name><surname>Stauffer</surname><given-names>WR</given-names></name>, <name><surname>Lak</surname><given-names>A</given-names></name>, <name><surname>Yang</surname><given-names>A</given-names></name>, <name><surname>Borel</surname><given-names>M</given-names></name>, <name><surname>Paulsen</surname><given-names>O</given-names></name>, <name><surname>Boyden</surname><given-names>ES</given-names></name>, <article-title>Schultz W: Dopamine neuron-specific optogenetic stimulation in rhesus macaques</article-title>. <source>Cell</source>
<year>2016</year>, <volume>166</volume>:<fpage>1564</fpage>&#x02013;<lpage>1571 e1566</lpage>.<pub-id pub-id-type="pmid">27610576</pub-id></mixed-citation></p><p id="P46">A novel combination of viral vectors was used to achieve cell type-specific channelrhodopsin expression in Rhesus macaque dopamine neurons. Dopamine neurons responded more strongly to stimuli that predicted optical stimulation, than to stimuli that did not, and the monkeys&#x02019; choice behavior reflected this; they chose the options associated with stimulation with greater frequency.</p></note></ref><ref id="R26"><label>26.&#x02022;&#x02022;</label><note><p id="P47"><mixed-citation publication-type="journal" id="P47-gen-1"><name><surname>Steinberg</surname><given-names>EE</given-names></name>, <name><surname>Keiflin</surname><given-names>R</given-names></name>, <name><surname>Boivin</surname><given-names>JR</given-names></name>, <name><surname>Witten</surname><given-names>IB</given-names></name>, <name><surname>Deisseroth</surname><given-names>K</given-names></name>, <name><surname>Janak</surname><given-names>PH</given-names></name>: <article-title>A causal link between prediction errors, dopamine neurons and learning</article-title>. <source>Nat Neurosci</source>
<year>2013</year>, <volume>16</volume>:<fpage>966</fpage>&#x02013;<lpage>973</lpage>.<pub-id pub-id-type="pmid">23708143</pub-id></mixed-citation></p><p id="P48">Using a &#x02018;blocking&#x02019; paradigm, the authors show that phasic dopamine activations &#x02014; positive prediction error responses &#x02014; are sufficient to cause learning.</p></note></ref><ref id="R27"><label>27.</label><mixed-citation publication-type="journal"><name><surname>Tan</surname><given-names>KR</given-names></name>, <name><surname>Yvon</surname><given-names>C</given-names></name>, <name><surname>Turiault</surname><given-names>M</given-names></name>, <name><surname>Mirzabekov</surname><given-names>JJ</given-names></name>, <name><surname>Doehner</surname><given-names>J</given-names></name>, <name><surname>Labouebe</surname><given-names>G</given-names></name>, <name><surname>Deisseroth</surname><given-names>K</given-names></name>, <name><surname>Tye</surname><given-names>KM</given-names></name>, <name><surname>Luscher</surname><given-names>C</given-names></name>: <article-title>GABA neurons of the VTA drive conditioned place aversion</article-title>. <source>Neuron</source>
<year>2012</year>, <volume>73</volume>:<fpage>1173</fpage>&#x02013;<lpage>1183</lpage>.<pub-id pub-id-type="pmid">22445344</pub-id></mixed-citation></ref><ref id="R28"><label>28.</label><mixed-citation publication-type="journal"><name><surname>van Zessen</surname><given-names>R</given-names></name>, <name><surname>Phillips</surname><given-names>JL</given-names></name>, <name><surname>Budygin</surname><given-names>EA</given-names></name>, <name><surname>Stuber</surname><given-names>GD</given-names></name>: <article-title>Activation of VTA GABA neurons disrupts reward consumption</article-title>. <source>Neuron</source>
<year>2012</year>, <volume>73</volume>:<fpage>1184</fpage>&#x02013;<lpage>1194</lpage>.<pub-id pub-id-type="pmid">22445345</pub-id></mixed-citation></ref><ref id="R29"><label>29.</label><mixed-citation publication-type="journal"><name><surname>Hamid</surname><given-names>AA</given-names></name>, <name><surname>Pettibone</surname><given-names>JR</given-names></name>, <name><surname>Mabrouk</surname><given-names>OS</given-names></name>, <name><surname>Hetrick</surname><given-names>VL</given-names></name>, <name><surname>Schmidt</surname><given-names>R</given-names></name>, <name><surname>Vander Weele</surname><given-names>CM</given-names></name>, <name><surname>Kennedy</surname><given-names>RT</given-names></name>, <name><surname>Aragona</surname><given-names>BJ</given-names></name>, <name><surname>Berke</surname><given-names>JD</given-names></name>: <article-title>Mesolimbic dopamine signals the value of work</article-title>. <source>Nat Neurosci</source>
<year>2016</year>, <volume>19</volume>:<fpage>117</fpage>&#x02013;<lpage>126</lpage>.<pub-id pub-id-type="pmid">26595651</pub-id></mixed-citation></ref><ref id="R30"><label>30.</label><mixed-citation publication-type="journal"><name><surname>Parker</surname><given-names>NF</given-names></name>, <name><surname>Cameron</surname><given-names>CM</given-names></name>, <name><surname>Taliaferro</surname><given-names>JP</given-names></name>, <name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Choi</surname><given-names>JY</given-names></name>, <name><surname>Davidson</surname><given-names>TJ</given-names></name>, <name><surname>Daw</surname><given-names>ND</given-names></name>, <name><surname>Witten</surname><given-names>IB</given-names></name>: <article-title>Reward and choice encoding in terminals of midbrain dopamine neurons depends on striatal target</article-title>. <source>Nat Neurosci</source>
<year>2016</year>, <volume>19</volume>:<fpage>845</fpage>&#x02013;<lpage>854</lpage>.<pub-id pub-id-type="pmid">27110917</pub-id></mixed-citation></ref><ref id="R31"><label>31.</label><mixed-citation publication-type="journal"><name><surname>Eshel</surname><given-names>N</given-names></name>, <name><surname>Tian</surname><given-names>J</given-names></name>, <name><surname>Bukwich</surname><given-names>M</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>: <article-title>Dopamine neurons share common response function for reward prediction error</article-title>. <source>Nat Neurosci</source>
<year>2016</year>, <volume>19</volume>:<fpage>479</fpage>&#x02013;<lpage>486</lpage>.<pub-id pub-id-type="pmid">26854803</pub-id></mixed-citation></ref><ref id="R32"><label>32.&#x02022;&#x02022;</label><note><p id="P49"><mixed-citation publication-type="journal" id="P49-gen-1"><name><surname>Eshel</surname><given-names>N</given-names></name>, <name><surname>Bukwich</surname><given-names>M</given-names></name>, <name><surname>Rao</surname><given-names>V</given-names></name>, <name><surname>Hemmelder</surname><given-names>V</given-names></name>, <name><surname>Tian</surname><given-names>J</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>: <article-title>Arithmetic and local circuitry underlying dopamine prediction errors</article-title>. <source>Nature</source>
<year>2015</year>, <volume>525</volume>:<fpage>243</fpage>&#x02013;<lpage>246</lpage>.<pub-id pub-id-type="pmid">26322583</pub-id></mixed-citation></p><p id="P50">Reward prediction errors are defined as received minus predicted reward. Therefore, subtraction is the fundamental operation guiding the prediction error algorithm. Recordings from optogenetically identified dopamine neurons revealed that the reward predictions reduced dopamine reward responses, to range of different reward sizes, by a constant amount. This finding confirms subtraction as the algorithmic principle governing phasic dopamine responses.</p></note></ref><ref id="R33"><label>33.</label><mixed-citation publication-type="journal"><name><surname>Sharpe</surname><given-names>MJ</given-names></name>, <name><surname>Marchant</surname><given-names>NJ</given-names></name>, <name><surname>Whitaker</surname><given-names>LR</given-names></name>, <name><surname>Richie</surname><given-names>CT</given-names></name>, <name><surname>Zhang</surname><given-names>YJ</given-names></name>, <name><surname>Campbell</surname><given-names>EJ</given-names></name>, <name><surname>Koivula</surname><given-names>PP</given-names></name>, <name><surname>Necarsulmer</surname><given-names>JC</given-names></name>, <name><surname>Mejias-Aponte</surname><given-names>C</given-names></name>, <name><surname>Morales</surname><given-names>M</given-names></name>
<etal/>: <article-title>Lateral hypothalamic GABAergic neurons encode reward predictions that are relayed to the ventral tegmental area to regulate learning</article-title>. <source>Curr Biol</source>
<year>2017</year>, <volume>27</volume>:<fpage>2089</fpage>&#x02013;<lpage>2100 e2085</lpage>.<pub-id pub-id-type="pmid">28690111</pub-id></mixed-citation></ref><ref id="R34"><label>34.&#x02022;&#x02022;</label><note><p id="P51"><mixed-citation publication-type="journal" id="P51-gen-1"><name><surname>Matsumoto</surname><given-names>H</given-names></name>, <name><surname>Tian</surname><given-names>J</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>, <name><surname>Watabe-Uchida</surname><given-names>M</given-names></name>: <article-title>Midbrain dopamine neurons signal aversion in a reward-context-dependent manner</article-title>. <source>Elife</source>
<year>2016</year>:<fpage>5</fpage>.</mixed-citation></p><p id="P52">Dopamine responses to aversive stimuli were dependent on reward context. In behavioral contexts where reward was rarely delivered, dopamine neurons were mostly inhibited by air-puff responses. In behavioral contexts where reward was delivered often, many dopamine neurons responded with a short-latency activation to air-puff. This result demonstrates that dopamine responses to aversive stimuli are sensitive to reward context, and highlight the importance of considering behavioral context when interpreting dopamine activations.</p></note></ref><ref id="R35"><label>35.</label><mixed-citation publication-type="book"><name><surname>Rescorla</surname><given-names>RA</given-names></name>, <name><surname>Wagner</surname><given-names>AR</given-names></name>: <chapter-title>A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and non reinforcement</chapter-title> In <source>Classical Conditioning II: Current Research and Theory</source>. Edited by <name><surname>Black</surname><given-names>AH</given-names></name>, <name><surname>Prokasy</surname><given-names>WF</given-names></name>. <publisher-name>Appleton-Century-Crofts</publisher-name>; <year>1972</year>:<fpage>64</fpage>&#x02013;<lpage>99</lpage>.</mixed-citation></ref><ref id="R36"><label>36.</label><mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>W</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>, <name><surname>Montague</surname><given-names>PR</given-names></name>: <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>
<year>1997</year>, <volume>275</volume>:<fpage>1593</fpage>&#x02013;<lpage>1599</lpage>.<pub-id pub-id-type="pmid">9054347</pub-id></mixed-citation></ref><ref id="R37"><label>37.</label><mixed-citation publication-type="journal"><name><surname>Montague</surname><given-names>PR</given-names></name>, <name><surname>Dayan</surname><given-names>P</given-names></name>, <name><surname>Sejnowski</surname><given-names>TJ</given-names></name>: <article-title>A framework for mesencephalic dopamine systems based on predictive Hebbian learning</article-title>. <source>J Neurosci</source>
<year>1996</year>, <volume>16</volume>:<fpage>1936</fpage>&#x02013;<lpage>1947</lpage>.<pub-id pub-id-type="pmid">8774460</pub-id></mixed-citation></ref><ref id="R38"><label>38.</label><mixed-citation publication-type="journal"><name><surname>Louie</surname><given-names>K</given-names></name>, <name><surname>Grattan</surname><given-names>LE</given-names></name>, <name><surname>Glimcher</surname><given-names>PW</given-names></name>: <article-title>Reward value-based gain control: divisive normalization in parietal cortex</article-title>. <source>J Neurosci</source>
<year>2011</year>, <volume>31</volume>:<fpage>10627</fpage>&#x02013;<lpage>10639</lpage>.<pub-id pub-id-type="pmid">21775606</pub-id></mixed-citation></ref><ref id="R39"><label>39.</label><mixed-citation publication-type="journal"><name><surname>Heeger</surname><given-names>DJ</given-names></name>: <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Vis Neurosci</source>
<year>1992</year>, <volume>9</volume>:<fpage>181</fpage>&#x02013;<lpage>197</lpage>.<pub-id pub-id-type="pmid">1504027</pub-id></mixed-citation></ref><ref id="R40"><label>40.</label><mixed-citation publication-type="journal"><name><surname>Tsai</surname><given-names>HC</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <name><surname>Adamantidis</surname><given-names>A</given-names></name>, <name><surname>Stuber</surname><given-names>GD</given-names></name>, <name><surname>Bonci</surname><given-names>A</given-names></name>, <name><surname>de Lecea</surname><given-names>L</given-names></name>, <name><surname>Deisseroth</surname><given-names>K</given-names></name>: <article-title>Phasic firing in dopaminergic neurons is sufficient for behavior conditioning</article-title>. <source>Science</source>
<year>2009</year>, <volume>324</volume>: <fpage>1080</fpage>&#x02013;<lpage>1084</lpage>.<pub-id pub-id-type="pmid">19389999</pub-id></mixed-citation></ref><ref id="R41"><label>41.</label><mixed-citation publication-type="journal"><name><surname>Sharpe</surname><given-names>MJ</given-names></name>, <name><surname>Chang</surname><given-names>CY</given-names></name>, <name><surname>Liu</surname><given-names>MA</given-names></name>, <name><surname>Batchelor</surname><given-names>HM</given-names></name>, <name><surname>Mueller</surname><given-names>LE</given-names></name>, <name><surname>Jones</surname><given-names>JL</given-names></name>, <name><surname>Niv</surname><given-names>Y</given-names></name>, <name><surname>Schoenbaum</surname><given-names>G</given-names></name>: <article-title>Dopamine transients are sufficient and necessary for acquisition of model-based associations</article-title>. <source>Nat Neurosci</source>
<year>2017</year>, <volume>20</volume>:<fpage>735</fpage>&#x02013;<lpage>742</lpage>.<pub-id pub-id-type="pmid">28368385</pub-id></mixed-citation></ref><ref id="R42"><label>42.</label><mixed-citation publication-type="journal"><name><surname>Witten</surname><given-names>IB</given-names></name>, <name><surname>Steinberg</surname><given-names>EE</given-names></name>, <name><surname>Lee</surname><given-names>SY</given-names></name>, <name><surname>Davidson</surname><given-names>TJ</given-names></name>, <name><surname>Zalocusky</surname><given-names>KA</given-names></name>, <name><surname>Brodsky</surname><given-names>M</given-names></name>, <name><surname>Yizhar</surname><given-names>O</given-names></name>, <name><surname>Cho</surname><given-names>SL</given-names></name>, <name><surname>Gong</surname><given-names>S</given-names></name>, <name><surname>Ramakrishnan</surname><given-names>C</given-names></name>
<etal/>: <article-title>Recombinase-driver rat lines: tools, techniques, and optogenetic application to dopamine-mediated reinforcement</article-title>. <source>Neuron</source>
<year>2011</year>, <volume>72</volume>:<fpage>721</fpage>&#x02013;<lpage>733</lpage>.<pub-id pub-id-type="pmid">22153370</pub-id></mixed-citation></ref><ref id="R43"><label>43.</label><mixed-citation publication-type="journal"><name><surname>Waelti</surname><given-names>P</given-names></name>, <name><surname>Dickinson</surname><given-names>A</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Dopamine responses comply with basic assumptions of formal learning theory</article-title>. <source>Nature</source>
<year>2001</year>, <volume>412</volume>:<fpage>43</fpage>&#x02013;<lpage>48</lpage>.<pub-id pub-id-type="pmid">11452299</pub-id></mixed-citation></ref><ref id="R44"><label>44.</label><mixed-citation publication-type="journal"><name><surname>Lattal</surname><given-names>KM</given-names></name>, <name><surname>Nakajima</surname><given-names>S</given-names></name>: <article-title>Overexpectation in appetitive Pavlovian and instrumental conditioning</article-title>. <source>Anim Learn Behav</source>
<year>1998</year>, <volume>26</volume>:<fpage>351</fpage>&#x02013;<lpage>360</lpage>.</mixed-citation></ref><ref id="R45"><label>45.</label><mixed-citation publication-type="journal"><name><surname>Rescorla</surname><given-names>RA</given-names></name>: <article-title>Spontaneous recovery from overexpectation</article-title>. <source>Learn Behav</source>
<year>2006</year>, <volume>34</volume>:<fpage>13</fpage>&#x02013;<lpage>20</lpage>.<pub-id pub-id-type="pmid">16786880</pub-id></mixed-citation></ref><ref id="R46"><label>46.</label><mixed-citation publication-type="journal"><name><surname>Rescorla</surname><given-names>RA</given-names></name>: <article-title>Renewal after overexpectation</article-title>. <source>Learn Behav</source>
<year>2007</year>, <volume>35</volume>:<fpage>19</fpage>&#x02013;<lpage>26</lpage>.<pub-id pub-id-type="pmid">17557388</pub-id></mixed-citation></ref><ref id="R47"><label>47.</label><mixed-citation publication-type="journal"><name><surname>Doll</surname><given-names>BB</given-names></name>, <name><surname>Simon</surname><given-names>DA</given-names></name>, <name><surname>Daw</surname><given-names>ND</given-names></name>: <article-title>The ubiquity of model-based reinforcement learning</article-title>. <source>Curr Opin Neurobiol</source>
<year>2012</year>, <volume>22</volume>:<fpage>1075</fpage>&#x02013;<lpage>1081</lpage>.<pub-id pub-id-type="pmid">22959354</pub-id></mixed-citation></ref><ref id="R48"><label>48.</label><mixed-citation publication-type="journal"><name><surname>Bromberg-Martin</surname><given-names>ES</given-names></name>, <name><surname>Matsumoto</surname><given-names>M</given-names></name>, <name><surname>Hong</surname><given-names>S</given-names></name>, <name><surname>Hikosaka</surname><given-names>O</given-names></name>: <article-title>A pallidus-habenula-dopamine pathway signals inferred stimulus values</article-title>. <source>J Neurophysiol</source>
<year>2010</year>, <volume>104</volume>:<fpage>1068</fpage>&#x02013;<lpage>1076</lpage>.<pub-id pub-id-type="pmid">20538770</pub-id></mixed-citation></ref><ref id="R49"><label>49.</label><mixed-citation publication-type="journal"><name><surname>Papageorgiou</surname><given-names>GK</given-names></name>, <name><surname>Baudonnat</surname><given-names>M</given-names></name>, <name><surname>Cucca</surname><given-names>F</given-names></name>, <name><surname>Walton</surname><given-names>ME</given-names></name>: <article-title>Mesolimbic dopamine encodes prediction errors in a state-dependent manner</article-title>. <source>Cell Rep</source>
<year>2016</year>, <volume>15</volume>:<fpage>221</fpage>&#x02013;<lpage>228</lpage>.<pub-id pub-id-type="pmid">27050518</pub-id></mixed-citation></ref><ref id="R50"><label>50.</label><mixed-citation publication-type="book"><name><surname>von Neumann</surname><given-names>J</given-names></name>, <name><surname>Morgenstern</surname><given-names>O</given-names></name>, <name><surname>Kuhn</surname><given-names>HW</given-names></name>, <name><surname>Rubinstein</surname><given-names>A</given-names></name>: <source>Theory of Games and Economic Behavior (60th Anniversary Commemorative Edition)</source>. <publisher-name>Princeton University Press</publisher-name>; <year>1944</year>.</mixed-citation></ref><ref id="R51"><label>51.</label><mixed-citation publication-type="journal"><name><surname>Genest</surname><given-names>W</given-names></name>, <name><surname>Stauffer</surname><given-names>WR</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Utility functions predict variance and skewness risk preferences in monkeys</article-title>. <source>Proc Natl Acad Sci U S A</source>
<year>2016</year>, <volume>113</volume>:<fpage>8402</fpage>&#x02013;<lpage>8407</lpage>.<pub-id pub-id-type="pmid">27402743</pub-id></mixed-citation></ref><ref id="R52"><label>52.</label><mixed-citation publication-type="journal"><name><surname>Morris</surname><given-names>G</given-names></name>, <name><surname>Nevet</surname><given-names>A</given-names></name>, <name><surname>Arkadir</surname><given-names>D</given-names></name>, <name><surname>Vaadia</surname><given-names>E</given-names></name>, <name><surname>Bergman</surname><given-names>H</given-names></name>: <article-title>Midbrain dopamine neurons encode decisions for future action</article-title>. <source>Nat Neurosci</source>
<year>2006</year>, <volume>9</volume>:<fpage>1057</fpage>&#x02013;<lpage>1063</lpage>.<pub-id pub-id-type="pmid">16862149</pub-id></mixed-citation></ref><ref id="R53"><label>53.</label><mixed-citation publication-type="journal"><name><surname>McDevitt</surname><given-names>RA</given-names></name>, <name><surname>Tiran-Cappello</surname><given-names>A</given-names></name>, <name><surname>Shen</surname><given-names>H</given-names></name>, <name><surname>Balderas</surname><given-names>I</given-names></name>, <name><surname>Britt</surname><given-names>JP</given-names></name>, <name><surname>Marino</surname><given-names>RAM</given-names></name>, <name><surname>Chung</surname><given-names>SL</given-names></name>, <name><surname>Richie</surname><given-names>CT</given-names></name>, <name><surname>Harvey</surname><given-names>BK</given-names></name>, <name><surname>Bonci</surname><given-names>A</given-names></name>: <article-title>Serotonergic versus nonserotonergic dorsal raphe projection neurons: differential participation in reward circuitry</article-title>. <source>Cell Rep</source>
<year>2014</year>, <volume>8</volume>:<fpage>1857</fpage>&#x02013;<lpage>1869</lpage>.<pub-id pub-id-type="pmid">25242321</pub-id></mixed-citation></ref><ref id="R54"><label>54.</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Hu</surname><given-names>F</given-names></name>, <name><surname>Lu</surname><given-names>Y</given-names></name>, <name><surname>Ma</surname><given-names>M</given-names></name>, <name><surname>Feng</surname><given-names>Q</given-names></name>, <name><surname>Zhang</surname><given-names>J-e</given-names></name>, <name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Zeng</surname><given-names>J</given-names></name>
<etal/> : <article-title>Dorsal raphe neurons signal reward through 5-HT and glutamate</article-title>. <source>Neuron</source>
<year>2014</year>, <volume>81</volume>:<fpage>1360</fpage>&#x02013;<lpage>1374</lpage>.<pub-id pub-id-type="pmid">24656254</pub-id></mixed-citation></ref><ref id="R55"><label>55.</label><mixed-citation publication-type="journal"><name><surname>Cohen</surname><given-names>JY</given-names></name>, <name><surname>Haesler</surname><given-names>S</given-names></name>, <name><surname>Vong</surname><given-names>L</given-names></name>, <name><surname>Lowell</surname><given-names>BB</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>: <article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title>. <source>Nature</source>
<year>2012</year>, <volume>482</volume>:<fpage>85</fpage>&#x02013;<lpage>88</lpage>.<pub-id pub-id-type="pmid">22258508</pub-id></mixed-citation></ref><ref id="R56"><label>56.</label><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Zhong</surname><given-names>W</given-names></name>, <name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Feng</surname><given-names>Q</given-names></name>, <name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, <name><surname>Jia</surname><given-names>C</given-names></name>, <name><surname>Hu</surname><given-names>F</given-names></name>, <name><surname>Zeng</surname><given-names>J</given-names></name>, <name><surname>Guo</surname><given-names>Q</given-names></name>
<etal/>: <article-title>Serotonin neurons in the dorsal raphe nucleus encode reward signals</article-title>. <source>Nat Commun</source>
<year>2016</year>, <volume>7</volume>:<fpage>10503</fpage>.<pub-id pub-id-type="pmid">26818705</pub-id></mixed-citation></ref><ref id="R57"><label>57.</label><mixed-citation publication-type="journal"><name><surname>Matsumoto</surname><given-names>M</given-names></name>, <name><surname>Hikosaka</surname><given-names>O</given-names></name>: <article-title>Lateral habenula as a source of negative reward signals in dopamine neurons</article-title>. <source>Nature</source>
<year>2007</year>, <volume>447</volume>:<fpage>1111</fpage>&#x02013;<lpage>1115</lpage>.<pub-id pub-id-type="pmid">17522629</pub-id></mixed-citation></ref><ref id="R58"><label>58.</label><mixed-citation publication-type="journal"><name><surname>Ji</surname><given-names>H</given-names></name>, <name><surname>Shepard</surname><given-names>PD</given-names></name>: <article-title>Lateral habenula stimulation inhibits rat midbrain dopamine neurons through a GABA(A) receptor-mediated mechanism</article-title>. <source>J Neurosci</source>
<year>2007</year>, <volume>27</volume>:<fpage>6923</fpage>&#x02013;<lpage>6930</lpage>.<pub-id pub-id-type="pmid">17596440</pub-id></mixed-citation></ref><ref id="R59"><label>59.</label><mixed-citation publication-type="journal"><name><surname>Christoph</surname><given-names>GR</given-names></name>, <name><surname>Leonzio</surname><given-names>RJ</given-names></name>, <name><surname>Wilcox</surname><given-names>KS</given-names></name>: <article-title>Stimulation of the lateral habenula inhibits dopamine-containing neurons in the substantia nigra and ventral tegmental area of the rat</article-title>. <source>J Neurosci</source>
<year>1986</year>, <volume>6</volume>:<fpage>613</fpage>&#x02013;<lpage>619</lpage>.<pub-id pub-id-type="pmid">3958786</pub-id></mixed-citation></ref><ref id="R60"><label>60.</label><mixed-citation publication-type="journal"><name><surname>Stamatakis</surname><given-names>AM</given-names></name>, <name><surname>Stuber</surname><given-names>GD</given-names></name>: <article-title>Activation of lateral habenula inputs to the ventral midbrain promotes behavioral avoidance</article-title>. <source>Nat Neurosci</source>
<year>2012</year>, <volume>15</volume>:<fpage>1105</fpage>&#x02013;<lpage>1107</lpage>.<pub-id pub-id-type="pmid">22729176</pub-id></mixed-citation></ref><ref id="R61"><label>61.</label><mixed-citation publication-type="journal"><name><surname>Lammel</surname><given-names>S</given-names></name>, <name><surname>Hetzel</surname><given-names>A</given-names></name>, <name><surname>Hackel</surname><given-names>O</given-names></name>, <name><surname>Jones</surname><given-names>I</given-names></name>, <name><surname>Liss</surname><given-names>B</given-names></name>, <name><surname>Roeper</surname><given-names>J</given-names></name>: <article-title>Unique properties of mesoprefrontal neurons within a dual mesocorticolimbic dopamine system</article-title>. <source>Neuron</source>
<year>2008</year>, <volume>57</volume>:<fpage>760</fpage>&#x02013;<lpage>773</lpage>.<pub-id pub-id-type="pmid">18341995</pub-id></mixed-citation></ref><ref id="R62"><label>62.</label><mixed-citation publication-type="journal"><name><surname>Grace</surname><given-names>AA</given-names></name>, <name><surname>Bunney</surname><given-names>BS</given-names></name>: <article-title>Intracellular and extracellular electrophysiology of nigral dopaminergic neurons &#x02014; 1. Identification and characterization</article-title>. <source>Neuroscience</source>
<year>1983</year>, <volume>10</volume>:<fpage>301</fpage>&#x02013;<lpage>315</lpage>.<pub-id pub-id-type="pmid">6633863</pub-id></mixed-citation></ref><ref id="R63"><label>63.</label><mixed-citation publication-type="journal"><name><surname>Bunney</surname><given-names>BS</given-names></name>, <name><surname>Aghajanian</surname><given-names>GK</given-names></name>, <name><surname>Roth</surname><given-names>RH</given-names></name>: <article-title>Comparison of effects of L-dopa, amphetamine and apomorphine on firing rate of rat dopaminergic neurones</article-title>. <source>Nat New Biol</source>
<year>1973</year>, <volume>245</volume>:<fpage>123</fpage>&#x02013;<lpage>125</lpage>.<pub-id pub-id-type="pmid">4518113</pub-id></mixed-citation></ref><ref id="R64"><label>64.</label><mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>W</given-names></name>, <name><surname>Romo</surname><given-names>R</given-names></name>: <article-title>Responses of nigrostriatal dopamine neurons to high-intensity somatosensory stimulation in the anesthetized monkey</article-title>. <source>J Neurophysiol</source>
<year>1987</year>, <volume>57</volume>:<fpage>201</fpage>&#x02013;<lpage>217</lpage>.<pub-id pub-id-type="pmid">3559672</pub-id></mixed-citation></ref><ref id="R65"><label>65.</label><mixed-citation publication-type="journal"><name><surname>Aebischer</surname><given-names>P</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>The activity of pars compacta neurons of the monkey substantia nigra is depressed by apomorphine</article-title>. <source>Neurosci Lett</source>
<year>1984</year>, <volume>50</volume>:<fpage>25</fpage>&#x02013;<lpage>29</lpage>.<pub-id pub-id-type="pmid">6493628</pub-id></mixed-citation></ref><ref id="R66"><label>66.</label><mixed-citation publication-type="journal"><name><surname>Mirenowicz</surname><given-names>J</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Preferential activation of midbrain dopamine neurons by appetitive rather than aversive stimuli</article-title>. <source>Nature</source>
<year>1996</year>, <volume>379</volume>:<fpage>449</fpage>&#x02013;<lpage>451</lpage>.<pub-id pub-id-type="pmid">8559249</pub-id></mixed-citation></ref><ref id="R67"><label>67.</label><mixed-citation publication-type="journal"><name><surname>Brischoux</surname><given-names>F</given-names></name>, <name><surname>Chakraborty</surname><given-names>S</given-names></name>, <name><surname>Brierley</surname><given-names>DI</given-names></name>, <name><surname>Ungless</surname><given-names>MA</given-names></name>: <article-title>Phasic excitation of dopamine neurons in ventral VTA by noxious stimuli</article-title>. <source>Proc Natl Acad Sci</source>
<year>2009</year>, <volume>106</volume>:<fpage>4894</fpage>&#x02013;<lpage>4899</lpage>.<pub-id pub-id-type="pmid">19261850</pub-id></mixed-citation></ref><ref id="R68"><label>68</label><mixed-citation publication-type="journal"><name><surname>Lerner</surname><given-names>TN</given-names></name>, <name><surname>Shilyansky</surname><given-names>C</given-names></name>, <name><surname>Davidson</surname><given-names>TJ</given-names></name>, <name><surname>Evans</surname><given-names>KE</given-names></name>, <name><surname>Beier</surname><given-names>KT</given-names></name>, <name><surname>Zalocusky</surname><given-names>KA</given-names></name>, <name><surname>Crow</surname><given-names>AK</given-names></name>, <name><surname>Malenka</surname><given-names>RC</given-names></name>, <name><surname>Luo</surname><given-names>L</given-names></name>, <name><surname>Tomer</surname><given-names>R</given-names></name>
<etal/>: <article-title>Intact-brain analyses reveal distinct information carried by SNc dopamine subcircuits</article-title>. <source>Cell</source>
<year>2015</year>, <volume>162</volume>:<fpage>635</fpage>&#x02013;<lpage>647</lpage>.<pub-id pub-id-type="pmid">26232229</pub-id></mixed-citation></ref><ref id="R69"><label>69</label><mixed-citation publication-type="journal"><name><surname>Fiorillo</surname><given-names>CD</given-names></name>: <article-title>Two dimensions of value: dopamine neurons represent reward but not aversiveness</article-title>. <source>Science</source>
<year>2013</year>,<volume>341</volume>:<fpage>546</fpage>&#x02013;<lpage>549</lpage>.<pub-id pub-id-type="pmid">23908236</pub-id></mixed-citation></ref><ref id="R70"><label>70.</label><mixed-citation publication-type="journal"><name><surname>Fiorillo</surname><given-names>CD</given-names></name>, <name><surname>Yun</surname><given-names>SR</given-names></name>, <name><surname>Song</surname><given-names>MR</given-names></name>: <article-title>Diversity and homogeneity in responses of midbrain dopamine neurons</article-title>. <source>J Neurosci</source>
<year>2013</year>, <volume>33</volume>:<fpage>4693</fpage>&#x02013;<lpage>4709</lpage>.<pub-id pub-id-type="pmid">23486943</pub-id></mixed-citation></ref><ref id="R71"><label>71</label><mixed-citation publication-type="journal"><name><surname>Fiorillo</surname><given-names>CD</given-names></name>, <name><surname>Song</surname><given-names>MR</given-names></name>, <name><surname>Yun</surname><given-names>SR</given-names></name>: <article-title>Multiphasic temporal dynamics in responses of midbrain dopamine neurons to appetitive and aversive stimuli</article-title>. <source>J Neurosci</source>
<year>2013</year>, <volume>33</volume>:<fpage>4710</fpage>&#x02013;<lpage>4725</lpage>.<pub-id pub-id-type="pmid">23486944</pub-id></mixed-citation></ref><ref id="R72"><label>72</label><mixed-citation publication-type="journal"><name><surname>Matsumoto</surname><given-names>M</given-names></name>, <name><surname>Hikosaka</surname><given-names>O</given-names></name>: <article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title>. <source>Nature</source>
<year>2009</year>, <volume>459</volume>:<fpage>837</fpage>&#x02013;<lpage>841</lpage>.<pub-id pub-id-type="pmid">19448610</pub-id></mixed-citation></ref><ref id="R73"><label>73.</label><mixed-citation publication-type="journal"><name><surname>Menegas</surname><given-names>W</given-names></name>, <name><surname>Babayan</surname><given-names>BM</given-names></name>, <name><surname>Uchida</surname><given-names>N</given-names></name>, <name><surname>Watabe-Uchida</surname><given-names>M</given-names></name>: <article-title>Opposite initialization to novel cues in dopamine signaling in ventral and posterior striatum in mice</article-title>. <source>Elife</source>
<year>2017</year>:<fpage>6</fpage>.</mixed-citation></ref><ref id="R74"><label>74.</label><mixed-citation publication-type="journal"><name><surname>Howe</surname><given-names>MW</given-names></name>, <name><surname>Dombeck</surname><given-names>DA</given-names></name>: <article-title>Rapid signalling in distinct dopaminergic axons during locomotion and reward</article-title>. <source>Nature</source>
<year>2016</year>, <volume>535</volume>:<fpage>505</fpage>&#x02013;<lpage>510</lpage>.<pub-id pub-id-type="pmid">27398617</pub-id></mixed-citation></ref><ref id="R75"><label>75.</label><mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>W</given-names></name>, <name><surname>Ruffieux</surname><given-names>A</given-names></name>, <name><surname>Aebischer</surname><given-names>P</given-names></name>: <article-title>The activity of pars compacta neurons of the monkey substantia nigra in relation to motor activation</article-title>. <source>Exp Brain Res</source>
<year>1983</year>, <volume>51</volume>:<fpage>377</fpage>&#x02013;<lpage>387</lpage>.</mixed-citation></ref><ref id="R76"><label>76</label><mixed-citation publication-type="journal"><name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Dopamine reward prediction-error signalling: a two-component response</article-title>. <source>Nat Rev Neurosci</source>
<year>2016</year>, <volume>17</volume>:<fpage>183</fpage>&#x02013;<lpage>195</lpage>.<pub-id pub-id-type="pmid">26865020</pub-id></mixed-citation></ref><ref id="R77"><label>77.</label><mixed-citation publication-type="journal"><name><surname>Nomoto</surname><given-names>K</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>, <name><surname>Watanabe</surname><given-names>T</given-names></name>, <name><surname>Sakagami</surname><given-names>M</given-names></name>: <article-title>Temporally extended dopamine responses to perceptually demanding reward-predictive stimuli</article-title>. <source>J Neurosci</source>
<year>2010</year>, <volume>30</volume>:<fpage>10692</fpage>&#x02013;<lpage>10702</lpage>.<pub-id pub-id-type="pmid">20702700</pub-id></mixed-citation></ref><ref id="R78"><label>78.</label><mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>TW</given-names></name>, <name><surname>Wardill</surname><given-names>TJ</given-names></name>, <name><surname>Sun</surname><given-names>Y</given-names></name>, <name><surname>Pulver</surname><given-names>SR</given-names></name>, <name><surname>Renninger</surname><given-names>SL</given-names></name>, <name><surname>Baohan</surname><given-names>A</given-names></name>, <name><surname>Schreiter</surname><given-names>ER</given-names></name>, <name><surname>Kerr</surname><given-names>RA</given-names></name>, <name><surname>Orger</surname><given-names>MB</given-names></name>, <name><surname>Jayaraman</surname><given-names>V</given-names></name>
<etal/>: <article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title>. <source>Nature</source>
<year>2013</year>, <volume>499</volume>:<fpage>295</fpage>&#x02013;<lpage>300</lpage>.<pub-id pub-id-type="pmid">23868258</pub-id></mixed-citation></ref><ref id="R79"><label>79.</label><mixed-citation publication-type="journal"><name><surname>Kobayashi</surname><given-names>S</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Reward contexts extend dopamine signals to unrewarded stimuli</article-title>. <source>Curr Biol</source>
<year>2014</year>, <volume>24</volume>:<fpage>56</fpage>&#x02013;<lpage>62</lpage>.<pub-id pub-id-type="pmid">24332545</pub-id></mixed-citation></ref><ref id="R80"><label>80.</label><mixed-citation publication-type="journal"><name><surname>Sheafor</surname><given-names>PJ</given-names></name>, <name><surname>Gormezano</surname><given-names>I</given-names></name>: <article-title>Conditioning the rabbit&#x02019;s (<italic>Oryctolagus cuniculus</italic>) jaw-movement response: US magnitude effects on URs, CRs, and pseudo-CRs</article-title>. <source>J Comp Physiol Psychol</source>
<year>1972</year>, <volume>81</volume>:<fpage>449</fpage>&#x02013;<lpage>456</lpage>.<pub-id pub-id-type="pmid">4649185</pub-id></mixed-citation></ref><ref id="R81"><label>81.</label><mixed-citation publication-type="journal"><name><surname>Morris</surname><given-names>G</given-names></name>, <name><surname>Arkadir</surname><given-names>D</given-names></name>, <name><surname>Nevet</surname><given-names>A</given-names></name>, <name><surname>Vaadia</surname><given-names>E</given-names></name>, <name><surname>Bergman</surname><given-names>H</given-names></name>: <article-title>Coincident but distinct messages of midbrain dopamine and striatal tonically active neurons</article-title>. <source>Neuron</source>
<year>2004</year>, <volume>43</volume>:<fpage>133</fpage>&#x02013;<lpage>143</lpage>.<pub-id pub-id-type="pmid">15233923</pub-id></mixed-citation></ref><ref id="R82"><label>82.</label><mixed-citation publication-type="journal"><name><surname>Shen</surname><given-names>W</given-names></name>, <name><surname>Flajolet</surname><given-names>M</given-names></name>, <name><surname>Greengard</surname><given-names>P</given-names></name>, <name><surname>Surmeier</surname><given-names>DJ</given-names></name>: <article-title>Dichotomous dopaminergic control of striatal synaptic plasticity</article-title>. <source>Science</source>
<year>2008</year>, <volume>321</volume>:<fpage>848</fpage>&#x02013;<lpage>851</lpage>.<pub-id pub-id-type="pmid">18687967</pub-id></mixed-citation></ref><ref id="R83"><label>83.</label><mixed-citation publication-type="journal"><name><surname>Tai</surname><given-names>LH</given-names></name>, <name><surname>Lee</surname><given-names>AM</given-names></name>, <name><surname>Benavidez</surname><given-names>N</given-names></name>, <name><surname>Bonci</surname><given-names>A</given-names></name>, <name><surname>Wilbrecht</surname><given-names>L</given-names></name>: <article-title>Transient stimulation of distinct subpopulations of striatal neurons mimics changes in action value</article-title>. <source>Nat Neurosci</source>
<year>2012</year>, <volume>15</volume>:<fpage>1281</fpage>&#x02013;<lpage>1289</lpage>.<pub-id pub-id-type="pmid">22902719</pub-id></mixed-citation></ref><ref id="R84"><label>84.</label><mixed-citation publication-type="journal"><name><surname>Brzosko</surname><given-names>Z</given-names></name>, <name><surname>Zannone</surname><given-names>S</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>, <name><surname>Clopath</surname><given-names>C</given-names></name>, <name><surname>Paulsen</surname><given-names>O</given-names></name>: <article-title>Sequential neuromodulation of Hebbian plasticity offers mechanism for effective reward-based navigation</article-title>. <source>Elife</source>
<year>2017</year>:<fpage>6</fpage>.</mixed-citation></ref><ref id="R85"><label>85.</label><mixed-citation publication-type="journal"><name><surname>Marr</surname><given-names>D</given-names></name>: <article-title>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</article-title>. <source>Henry Holt and Company</source>; <year>1983</year>.</mixed-citation></ref><ref id="R86"><label>86.</label><mixed-citation publication-type="journal"><name><surname>Krakauer</surname><given-names>JW</given-names></name>, <name><surname>Ghazanfar</surname><given-names>AA</given-names></name>, <name><surname>Gomez-Marin</surname><given-names>A</given-names></name>, <name><surname>MacIver</surname><given-names>MA</given-names></name>, <name><surname>Poeppel</surname><given-names>D</given-names></name>: <article-title>Neuroscience needs behavior: correcting a reductionist bias</article-title>. <source>Neuron</source>
<year>2017</year>, <volume>93</volume>:<fpage>480</fpage>&#x02013;<lpage>490</lpage>.<pub-id pub-id-type="pmid">28182904</pub-id></mixed-citation></ref><ref id="R87"><label>87.</label><mixed-citation publication-type="journal"><name><surname>Tobler</surname><given-names>PN</given-names></name>, <name><surname>Fiorillo</surname><given-names>CD</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Adaptive coding of reward value by dopamine neurons</article-title>. <source>Science</source>
<year>2005</year>, <volume>307</volume>:<fpage>1642</fpage>&#x02013;<lpage>1645</lpage>.<pub-id pub-id-type="pmid">15761155</pub-id></mixed-citation></ref><ref id="R88"><label>88.</label><mixed-citation publication-type="journal"><name><surname>Fiorillo</surname><given-names>CD</given-names></name>, <name><surname>Tobler</surname><given-names>PN</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons</article-title>. <source>Science</source>
<year>2003</year>, <volume>299</volume>:<fpage>1898</fpage>&#x02013;<lpage>1902</lpage>.<pub-id pub-id-type="pmid">12649484</pub-id></mixed-citation></ref><ref id="R89"><label>89.</label><mixed-citation publication-type="journal"><name><surname>Nakahara</surname><given-names>H</given-names></name>, <name><surname>Itoh</surname><given-names>H</given-names></name>, <name><surname>Kawagoe</surname><given-names>R</given-names></name>, <name><surname>Takikawa</surname><given-names>Y</given-names></name>, <name><surname>Hikosaka</surname><given-names>O</given-names></name>: <article-title>Dopamine neurons can represent context-dependent prediction error</article-title>. <source>Neuron</source>
<year>2004</year>, <volume>41</volume>:<fpage>269</fpage>&#x02013;<lpage>280</lpage>.<pub-id pub-id-type="pmid">14741107</pub-id></mixed-citation></ref><ref id="R90"><label>90.</label><mixed-citation publication-type="journal"><name><surname>Kobayashi</surname><given-names>S</given-names></name>, <name><surname>Schultz</surname><given-names>W</given-names></name>: <article-title>Influence of reward delays on responses of dopamine neurons</article-title>. <source>J Neurosci</source>
<year>2008</year>, <volume>28</volume>:<fpage>7837</fpage>&#x02013;<lpage>7846</lpage>.<pub-id pub-id-type="pmid">18667616</pub-id></mixed-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Figure 1:</label><caption><p id="P53">Dopamine neurons reflect the behavioral computations of value. <bold>(a)</bold> Dopamine neurons represent a common scale of value. Monkeys indicated preference between different reward types by making choices. Orange and brown boxes represent the CSs that were associated with the different rewards, and that the monkeys chose between. &#x02018;Greater than&#x02019; symbols indicate more preferred, whereas tildes indicate choice indifference. Peri-Stimulus Time Histogram (PSTH) of dopamine responses to onset of visual reward-predicting CS. Individual PSTH are color and dash coded according to the CS. Dopamine responses were largest for the most preferred rewards, smallest for the least preferred rewards, and indistinguishable for rewards that the monkey was indifferent between. This figure was modified and reproduced with permission from Ref. [<xref rid="R20" ref-type="bibr">20</xref>]. <bold>(b)</bold> The mathematical relationship between subjective value (utility) and physical reward size was described by an S-shaped function (red line). Grey bars indicate dopamine responses to unpredicted rewards that varied in magnitude between 0.1 ml and 1.2 ml in 0.1 ml increments. Error bars are SEM across 16 neurons. This figure was modified and reproduced with permission from Ref. [<xref rid="R23" ref-type="bibr">23</xref>]. <bold>(c)</bold> Raster plot (top) and PSTH (bottom) of one dopamine neuron in response to the onset of a RDM stimulus. Data are divided according to the accuracy of the subsequent choice. Dopamine neurons were more active on trials when the monkey chose correctly (green), rather than incorrectly (red). Numbers along the side of the raster plot indicate RDM coherence. Shaded error bars on PSTH are SEM across trials. This figure was modified and reproduced with permission from Ref. [<xref rid="R19" ref-type="bibr">19</xref>]. <bold>(d)</bold> Dopamine neurons are silenced by distorted audio feedback (DAF) during bird song learning. Voltage traces (top) and raster plots (bottom) around normal (&#x02018;Normal&#x02019;) and distorted (&#x02018;DAF&#x02019;) audio feedback. This figure was modified and reproduced with permission from Ref. [<xref rid="R18" ref-type="bibr">18<sup>&#x02022;&#x02022;</sup></xref>].</p></caption><graphic xlink:href="nihms-961371-f0001"/></fig></floats-group></article>