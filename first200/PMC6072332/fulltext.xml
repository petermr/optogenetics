<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="article-commentary"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.0?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">eNeuro</journal-id><journal-id journal-id-type="iso-abbrev">eNeuro</journal-id><journal-id journal-id-type="hwp">eneuro</journal-id><journal-id journal-id-type="pmc">eneuro</journal-id><journal-id journal-id-type="publisher-id">eNeuro</journal-id><journal-title-group><journal-title>eNeuro</journal-title></journal-title-group><issn pub-type="epub">2373-2822</issn><publisher><publisher-name>Society for Neuroscience</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6072332</article-id><article-id pub-id-type="doi">10.1523/ENEURO.0168-18.2018</article-id><article-id pub-id-type="publisher-id">eN-COM-0168-18</article-id><article-categories><subj-group subj-group-type="hwp-journal-coll"><subject>1</subject><subject>1.10</subject></subj-group><subj-group subj-group-type="heading"><subject>Commentary</subject><subj-group><subject>Cognition and Behavior</subject></subj-group></subj-group></article-categories><title-group><article-title>Bidirectional Control of Risk-Seeking Behavior by the Basolateral Amygdala</article-title><alt-title alt-title-type="right-running-head">Role of BLA during Phases of Decision-Making</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6591-0983</contrib-id><name><surname>Cisneros-Franco</surname><given-names>J. Miguel</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-1446-3295</contrib-id><name><surname>de Villers-Sidani</surname><given-names>Etienne</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><aff id="aff1"><label>1</label>Department of Neurology and Neurosurgery, Montreal Neurological Institute, <institution>McGill University</institution>, Montreal, QC H3A 2B4, <country>Canada</country></aff><aff id="aff2"><label>2</label><institution>Centre for Research on Brain, Language, and Music</institution>, Montreal, QC H3G 2A8, <country>Canada</country></aff></contrib-group><author-notes><fn fn-type="other"><p>The authors declare no competing financial interests.</p></fn><fn fn-type="con"><p>Author contributions: J.M.C.-F. and E.d.V.-S. wrote the paper.</p></fn><fn fn-type="supported-by"><p>This work was supported by the Canadian Institutes of Health Research.</p></fn><corresp id="cor1">Correspondence should be addressed to J. Miguel Cisneros-Franco, 3801 University Street, Room 753, Montreal, QC H3A2B4, Canada, E-mail: <email>mike.cisneros-franco@mail.mcgill.ca</email>.</corresp></author-notes><pub-date pub-type="epreprint"><day>6</day><month>7</month><year>2018</year></pub-date><pub-date pub-type="epub"><day>2</day><month>8</month><year>2018</year></pub-date><pub-date pub-type="collection"><season>Jul-Aug</season><year>2018</year></pub-date><volume>5</volume><issue>4</issue><elocation-id>ENEURO.0168-18.2018</elocation-id><history><date date-type="received"><day>30</day><month>4</month><year>2018</year></date><date date-type="rev-recd"><day>26</day><month>6</month><year>2018</year></date><date date-type="accepted"><day>28</day><month>6</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Cisneros-Franco and de Villers-Sidani</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Cisneros-Franco and de Villers-Sidani</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International license</ext-link>, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="ENEURO.0168-18.2018.pdf"/><self-uri xlink:role="icon" xlink:href="enu00418267200g1.jpg"/><kwd-group><kwd>basolateral amygdale</kwd><kwd>decision-making</kwd><kwd>optogenetics</kwd><kwd>punishment</kwd><kwd>reward</kwd><kwd>risk
</kwd></kwd-group><counts><fig-count count="1"/><table-count count="0"/><equation-count count="0"/><ref-count count="24"/><page-count count="5"/><word-count count="3125"/></counts><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>July/August 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Significance Statement</title><p>Decision-making under risk entails the possibility of simultaneously receiving positive (reward) and negative (punishment) stimuli. To learn in this context, one must integrate conflicting information related to the magnitude of reward and the probability of punishment. Long-term inactivation of the basolateral amygdala (BLA) disrupts this process and increases risky behavior. In a recent study published in the <italic>Journal of Neuroscience</italic>, <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> showed that briefly inhibiting the BLA may result in increased or decreased risk-taking behavior, depending on the phase of the decision process in which BLA activity is disrupted. Here, we discuss the results and propose future experiments that could improve our understanding of how the BLA contributes to adaptive learning under risk and uncertainty.</p></sec><sec id="s10"><title/><p>In complex, &#x0201c;real-world&#x0201d; environments, choices made may result in both rewards and adverse outcomes, each associated with different and often-changing probabilities. Decision-making under risk and uncertainty requires sustained attention and constant updating of learned rules to adequately valuate available alternatives. During risky decision-making, rewarding or punishing outcomes encountered following each decision facilitate learning through positive or negative reinforcement, respectively (<xref rid="B22" ref-type="bibr">W&#x000e4;chter et al., 2009</xref>). How individuals react to such competing environmental cues has been the focus of numerous studies in decision neuroscience (<xref rid="B17" ref-type="bibr">Preuschoff et al., 2015</xref>). These studies show that cultural, social, and genetic factors shape risk preference, although transient internal states, such as mood, fatigue, or recent experience, may also influence an individual&#x02019;s propensity to risk-taking (<xref rid="B23" ref-type="bibr">Weber and Johnson, 2009</xref>).</p><p>Located at the crossroads of corticolimbic circuits that mediate reinforcement learning, the basolateral amygdala (BLA) responds to arousing stimuli of both positive and negative valence (<xref rid="B19" ref-type="bibr">Shabel and Janak, 2009</xref>) and is necessary for the establishment of reward associations (<xref rid="B1" ref-type="bibr">Baxter and Murray, 2002</xref>) and fear conditioning (<xref rid="B10" ref-type="bibr">Krabbe et al., 2017</xref>). This functional heterogeneity has made the BLA a prime target to study associative learning using risky decision-making tasks (RDTs), in which rodents have to choose between a small, &#x0201c;safe&#x0201d; food reward and a large, &#x0201c;risky&#x0201d; reward that might be paired with a punishment. Over the last decade, studies using RDTs have shown that pharmacological inactivation and lesions of the BLA increase risk-seeking behavior (<xref rid="B14" ref-type="bibr">Orsini et al., 2015</xref>; <xref rid="B16" ref-type="bibr">Piantadosi et al., 2017</xref>). However, studies with high temporal resolution allowing trial-by-trial manipulation of BLA activity are lacking. Therefore, it remains unknown whether increased risk-seeking behavior is the result of BLA loss-of-function specifically during the deliberation phase, i.e., in decision-making per se, and/or during the outcome phase, i.e., the associative phase of reward and punishment.</p><p>In a study published in the <italic>Journal of Neuroscience</italic>, <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> addressed this gap in knowledge by using optogenetics to inhibit BLA activity at three different phases of a RDT; namely, deliberation, outcome, and intertrial interval. The deliberation phase corresponded to the &#x02264;10-s period during which rats had to choose between two levers (safe, associated with a small reward, or risky, associated with a large reward that was accompanied by an increasing probability of a footshock). Lever choice marked the beginning of the 5-s outcome period during which reward (always) and punishment (if any) were delivered, followed by a variable intertrial interval that brought each trial&#x02019;s length to 40 s. Laser delivery occurred during one of the three phases and lasted &#x02264;5 s (<xref ref-type="fig" rid="F1">Fig. 1<italic>A</italic></xref>).</p><fig id="F1" fig-type="figure" orientation="portrait" position="float"><label>Figure 1.</label><caption><p>
<bold><italic>A</italic></bold>, Experimental paradigm used in <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref>. The RDT was divided in three phases: deliberation, outcome, and intertrial interval. Optogenetic inhibition of the BLA occurred during one of the three phases and lasted &#x02264;5 s. <bold><italic>B</italic></bold>, Reward (green) and punishment (red) are processed by distinct subpopulations within the BLA. Only major afferent and efferent BLA connections discussed in the text are shown. <bold><italic>C</italic></bold>, Concurrent delivery of a large reward alongside punishment results in conflicting information, of positive and negative valence, respectively, reaching the BLA. Hypothesis: in absence of <italic>no-Go</italic> inputs from BLA to CeA, NAc shell, and PFC, predominance of <italic>Go</italic> inputs to the NAc (notably from VTA) may bias the animal&#x02019;s perceived experience toward rewarding stimuli, thus increasing risky choice. R, rostral; C, caudal; M, medial; L, lateral.</p></caption><graphic xlink:href="enu0041826720001"/></fig><p>In the control condition, as expected, the likelihood of choosing the risky reward diminished as the probability of punishment increased. Interestingly, transient BLA inactivation yielded opposite results depending on the phase of the decision-making process at which it occurred. On the one hand, BLA inhibition during the deliberation phase decreased risky choice and resulted in a higher probability of performing a lose-shift, i.e., making a safe choice immediately after punishment. On the other hand, silencing of BLA neurons during delivery of a large, punished outcome, increased risky choice, and decreased the proportion of lose-shift trials.</p><p>How to reconcile such disparate results? One possible explanation comes from the fact that optogenetic inhibition reduced overall BLA activity, without cell-type specificity. Because the BLA receives inputs from and sends projections to different cortical and subcortical targets (<xref rid="B13" ref-type="bibr">O&#x02019;Neill et al., 2018</xref>), it is important to consider its functional and anatomic heterogeneity before discussing Orsini et al.&#x02019;s results.</p><p>Inputs reaching the BLA from the prefrontal cortex (PFC) and dopaminergic neurons in the ventral tegmental (VTA) modulate reward sensitivity. Disruption of PFC-to-BLA projections, pharmacological blockade of D<sub>1</sub> receptors (D<sub>1</sub>R), and D<sub>2</sub>R stimulation all reduce risky choice (<xref rid="B20" ref-type="bibr">St Onge et al., 2012</xref>; <xref rid="B11" ref-type="bibr">Larkin et al., 2016</xref>). D<sub>1</sub>R stimulation however may increase or decrease risky choice, depending on reward probabilities and individual risk-preferences (<xref rid="B11" ref-type="bibr">Larkin et al., 2016</xref>).</p><p>Regarding BLA outputs, recent evidence suggests that risk-seeking and risk-avoidance are mediated by distinct neuronal subpopulations within the BLA, which in turn project to segregated brain regions driving opposing outcomes (<xref rid="B12" ref-type="bibr">Namburi et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Beyeler et al., 2016, 2018</xref>). BLA neurons that synapse in the nucleus accumbens (NAc projectors) are preferentially excited to reward-predictive cues (<xref rid="B2" ref-type="bibr">Beyeler et al., 2016</xref>), whereas central amygdala (CeA) projectors and medial PFC (mPFC) projectors are preferentially excited to cues associated with an aversive outcome (<xref rid="B4" ref-type="bibr">Burgos-Robles et al., 2017</xref>; <xref ref-type="fig" rid="F1">Fig. 1<italic>B</italic></xref>). In contrast, neurons projecting to the ventral hippocampus do not show a preference for either positive or negative stimuli (<xref rid="B2" ref-type="bibr">Beyeler et al., 2016</xref>). Moreover, a study by the same research group showed that specific activation of BLA NAc projectors and CeA projectors facilitate positive and negative reinforcement learning, respectively (<xref rid="B12" ref-type="bibr">Namburi et al., 2015</xref>). Taken together, these results suggest that distinct BLA subpopulations are engaged differently at discrete time-points of the decision-making process. Hence, it is possible that non-specific inhibition of pre- and/or postsynaptic activity within the amygdala might have selective effects depending on the phase of the decision-making process that is disrupted.</p></sec><sec id="s2"><title>BLA Inhibition during Delivery of Large, Punished Outcome Increases Risky Choice</title><p>Delivery of a large reward alongside punishment results in conflicting positive- and negative-valence signals simultaneously reaching the BLA. The increase in risk-seeking behavior reported by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> with BLA inactivation during delivery of a large, punished reward suggests that intact BLA function contributes to the integration of reward magnitude and punishment-related information.</p><p>Given the role of BLA NAc-, CeA-, and mPFC-projecting neurons in reinforcement learning, it seems sensible to hypothesize that conflicting outcomes are represented in the BLA by opposing yet complementary activity of these neuronal populations. The increase of risky choice and the reduction in the number of lose-shift trials observed by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> suggests that, in the presence of conflicting inputs, activity of CeA and/or mPFC projectors is more determinant than that of NAc projectors in informing subsequent decisions. If, indeed, discrete BLA subpopulations are preferentially recruited during the outcome phase, inhibition of all projection neurons would have an impact only on the neurons that are normally activated during said phase. This raises the question of why, in the absence of BLA to NAc inputs, risk-seeking behavior is not affected. According to our current understanding of NAc reward circuitry, there are at least two possible, non-mutually exclusive, explanations for this result. The first possible explanation relates to the functional and anatomic subdivisions of the NAc, while the second has to do with other brain structures besides the BLA that feed into the NAc.</p><p>First, the BLA projects to both the lateral (&#x0201c;core&#x0201d;) and medial (&#x0201c;shell&#x0201d;) subdivisions of the NAc. A recent study showed that pharmacological inactivation of either BLA or NAc shell during a RDT increased risky behavior, suggesting that both structures suppress punished reward seeking (<xref rid="B16" ref-type="bibr">Piantadosi et al., 2017</xref>). In contrast, NAc core inactivation reduced overall responding, even in the absence of any risk, suggesting that NAc core facilitates reward-seeking, independent of motivational conflict (<xref rid="B16" ref-type="bibr">Piantadosi et al., 2017</xref>). It is therefore possible that non-specific BLA inactivation affected a BLA-NAc shell circuit responsible for the punishment-induced inhibition of behavior.</p><p>Second, the NAc is a major target of dopaminergic VTA neurons, which encode the value of predicted and observed rewards and respond strongly to rewards during the course of learning (<xref rid="B7" ref-type="bibr">Hollerman and Schultz, 1998</xref>). Moreover, VTA stimulation following a &#x0201c;risky loss,&#x0201d; i.e., punishment in the absence of reward, increases risk preference (<xref rid="B21" ref-type="bibr">Stopper et al., 2014</xref>). Taken together, these observations indicate that BLA silencing during delivery of a large, punished reward might result in or resemble the effect of reduced NAc shell activity, effectively &#x0201c;releasing&#x0201d; the NAc core, which may also respond to strong VTA inputs that bias the animal&#x02019;s perceived experience toward rewarding stimuli (<xref ref-type="fig" rid="F1">Fig. 1<italic>C</italic></xref>).</p></sec><sec id="s3"><title>BLA Inhibition during Deliberation Decreases Risky Choice</title><p>The result of decreased risky choice with BLA inactivation during deliberation observed by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> appears to be at odds with previous reports using lesions and pharmacologic inhibition of the BLA (<xref rid="B14" ref-type="bibr">Orsini et al., 2015</xref>; <xref rid="B16" ref-type="bibr">Piantadosi et al., 2017</xref>). Nevertheless, as mentioned above, said techniques do not offer the time resolution needed to study the role of the BLA during different phases of the RDT, a limitation that was circumvented by the use of optogenetics. Therefore, the experiments conducted by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> demonstrate that previously observed deficits in decision-making following BLA inactivation are the result of BLA loss-of-function that specifically affected the integration of conflicting outcomes and not the deliberative process itself. Given that decreased risk-seeking behavior was elicited exclusively with BLA silencing during the deliberation phase, it remains to be seen which network(s) within the BLA inform decision-making during such a brief period, lasting no more than 5 s in the study by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref>. A viable approach to answer this question would be the use of optogenetics to identify (&#x0201c;phototag&#x0201d;) BLA subpopulations by simultaneously injecting a Cre-dependent opsin construct in the BLA and a construct carrying Cre recombinase in the structure where the population of interest projects (<xref rid="B3" ref-type="bibr">Beyeler et al., 2018</xref>). Should a neuronal BLA subpopulation be identified as key in decision-making during deliberation, this approach could be used in combination with computational models developed for functional neuroimaging to better characterize any observed activity patterns (<xref rid="B18" ref-type="bibr">Pr&#x000e9;vost et al., 2013</xref>). Of particular interest would be to test whether the BLA performs model-based computations, in which the value of actions are updated using a rich representation of the structure of the decision problem, as opposed to purely prediction-error driven model-free algorithms (<xref rid="B5" ref-type="bibr">Corrado and Doya, 2007</xref>).</p></sec><sec id="s4"><title>Concluding Remarks and Future Directions</title><p>The main contribution of the study by <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> is the demonstration that the BLA plays different roles at different behavioral phases of risky decision-making. While these findings may have implications for the study of impulse control disorders, it should be noted that certain aspects of risky decision-making can be encountered in everyday situations and may have real-life consequences with respect to personal finances. For instance, <xref rid="B9" ref-type="bibr">Knutson et al. (2011)</xref> showed that individuals who were better at positive reinforcement learning had more assets, whereas those who were more effective at learning from negative outcomes had less debt. In a subsequent study, the authors found that reduced impulse control, but not cognitive abilities, was the main factor that predicted an individual&#x02019;s susceptibility to investment fraud (<xref rid="B8" ref-type="bibr">Knutson and Samanez-Larkin, 2014</xref>).</p><p>Future studies may build on the work of <xref rid="B15" ref-type="bibr">Orsini et al. (2017)</xref> to further our understanding of how the BLA contributes to adaptive learning in the context of risk and uncertainty. To this end, we propose two avenues of research going forward. First, investigate if the effects of BLA inhibition vary as a function of individual differences in risk propensity. Although most subjects show a marked bias toward risk aversion, a few seem to prefer risk. Recent studies have shown that risk-seeking rats could be &#x0201c;converted&#x0201d; to risk-averse rats using phasic optogenetic stimulation of D<sub>2</sub>R neurons in the NAc (<xref rid="B24" ref-type="bibr">Zalocusky et al., 2016</xref>) or D<sub>2</sub>R agonists infused into the BLA (<xref rid="B11" ref-type="bibr">Larkin et al., 2016</xref>). Thus, a priori identification of risk-prone and risk-averse subjects may reveal whether acute BLA inhibition has the same effect on behavior regardless of previously established risk preference.</p><p>Second, it remains to be seen whether repeated transient manipulation of BLA activity over an extended period of time will result in significant and long-lasting changes in reward processing. For instance, chronic mPFC stimulation in rats reduces reward-seeking behavior and gives rise to brain-wide activity patterns that predict the onset and severity of anhedonia (<xref rid="B6" ref-type="bibr">Ferenczi et al., 2016</xref>). Given the numerous reciprocal connections between the BLA and other brain regions, including the mPFC, we posit that chronic manipulation of BLA activity could similarly change corticolimbic synchrony and alter reward sensitivity. Experiments using intermittent optogenetic or sustained chemogenetic manipulation of BLA activity could be used to test this hypothesis. Going forward, research with a focus on brain networks, rather than on specific isolated structures, may best reveal the mechanisms whereby different behaviors arise from common brain regions.</p></sec></body><back><ref-list content-type="nameDate"><title>References</title><ref id="B1"><mixed-citation publication-type="journal">
<string-name><surname>Baxter</surname>
<given-names>MG</given-names></string-name>, <string-name><surname>Murray</surname>
<given-names>EA</given-names></string-name> (<year>2002</year>) <article-title>The amygdala and reward</article-title>. <source>Nat Rev Neurosci</source>
<volume>3</volume>:<fpage>563</fpage>&#x02013;<lpage>573</lpage>. <pub-id pub-id-type="doi">10.1038/nrn875</pub-id><pub-id pub-id-type="pmid">12094212</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal">
<string-name><surname>Beyeler</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Namburi</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Glober</surname>
<given-names>GF</given-names></string-name>, <string-name><surname>Simonnet</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Calhoon</surname>
<given-names>GG</given-names></string-name>, <string-name><surname>Conyers</surname>
<given-names>GF</given-names></string-name>, <string-name><surname>Luck</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Wildes</surname>
<given-names>CP</given-names></string-name>, <string-name><surname>Tye</surname>
<given-names>KM</given-names></string-name> (<year>2016</year>) <article-title>Divergent routing of positive and negative information from the amygdala during memory retrieval</article-title>. <source>Neuron</source>
<volume>90</volume>:<fpage>348</fpage>&#x02013;<lpage>361</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.004</pub-id>
<?supplied-pmid 27041499?><pub-id pub-id-type="pmid">27041499</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal">
<string-name><surname>Beyeler</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Chang</surname>
<given-names>CJ</given-names></string-name>, <string-name><surname>Silvestre</surname>
<given-names>M</given-names></string-name>, <string-name><surname>L&#x000e9;v&#x000ea;que</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Namburi</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Wildes</surname>
<given-names>CP</given-names></string-name>, <string-name><surname>Tye</surname>
<given-names>KM</given-names></string-name> (<year>2018</year>) <article-title>Organization of valence-encoding and projection-defined neurons in the basolateral amygdala</article-title>. <source>Cell Rep</source>
<volume>22</volume>:<fpage>905</fpage>&#x02013;<lpage>918</lpage>. <pub-id pub-id-type="doi">10.1016/j.celrep.2017.12.097</pub-id>
<?supplied-pmid 29386133?><pub-id pub-id-type="pmid">29386133</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal">
<string-name><surname>Burgos-Robles</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Kimchi</surname>
<given-names>EY</given-names></string-name>, <string-name><surname>Izadmehr</surname>
<given-names>EM</given-names></string-name>, <string-name><surname>Porzenheim</surname>
<given-names>MJ</given-names></string-name>, <string-name><surname>Ramos-Guasp</surname>
<given-names>WA</given-names></string-name>, <string-name><surname>Nieh</surname>
<given-names>EH</given-names></string-name>, <string-name><surname>Felix-Ortiz</surname>
<given-names>AC</given-names></string-name>, <string-name><surname>Namburi</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Leppla</surname>
<given-names>CA</given-names></string-name>, <string-name><surname>Presbrey</surname>
<given-names>KN</given-names></string-name>, <string-name><surname>Anandalingam</surname>
<given-names>KK</given-names></string-name>, <string-name><surname>Pagan-Rivera</surname>
<given-names>PA</given-names></string-name>, <string-name><surname>Anahtar</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Beyeler</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Tye</surname>
<given-names>KM</given-names></string-name> (<year>2017</year>) <article-title>Amygdala inputs to prefrontal cortex guide behavior amid conflicting cues of reward and punishment</article-title>. <source>Nat Neurosci</source>
<volume>20</volume>:<fpage>824</fpage>&#x02013;<lpage>835</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4553</pub-id><pub-id pub-id-type="pmid">28436980</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal">
<string-name><surname>Corrado</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Doya</surname>
<given-names>K</given-names></string-name> (<year>2007</year>) <article-title>Understanding neural coding through the model-based analysis of decision making</article-title>. <source>J Neurosci</source>
<volume>27</volume>:<fpage>8178</fpage>&#x02013;<lpage>8180</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1590-07.2007</pub-id><pub-id pub-id-type="pmid">17670963</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal">
<string-name><surname>Ferenczi</surname>
<given-names>EA</given-names></string-name>, <string-name><surname>Zalocusky</surname>
<given-names>KA</given-names></string-name>, <string-name><surname>Liston</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Grosenick</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Warden</surname>
<given-names>MR</given-names></string-name>, <string-name><surname>Amatya</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Katovich</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Mehta</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Patenaude</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Ramakrishnan</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Kalanithi</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Etkin</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Knutson</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Glover</surname>
<given-names>GH</given-names></string-name>, <string-name><surname>Deisseroth</surname>
<given-names>K</given-names></string-name> (<year>2016</year>) <article-title>Prefrontal cortical regulation of brainwide circuit dynamics and reward-related behavior</article-title>. <source>Science</source>
<volume>351</volume>:<fpage>aac9698</fpage>.<pub-id pub-id-type="pmid">26722001</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal">
<string-name><surname>Hollerman</surname>
<given-names>JR</given-names></string-name>, <string-name><surname>Schultz</surname>
<given-names>W</given-names></string-name> (<year>1998</year>) <article-title>Dopamine neurons report an error in the temporal prediction of reward during learning</article-title>. <source>Nat Neurosci</source>
<volume>1</volume>:<fpage>304</fpage>&#x02013;<lpage>309</lpage>. <pub-id pub-id-type="doi">10.1038/1124</pub-id><pub-id pub-id-type="pmid">10195164</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="book">
<string-name><surname>Knutson</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Samanez-Larkin</surname>
<given-names>G</given-names></string-name> (<year>2014</year>) <source>Individual differences in susceptibility to investment fraud</source>, <publisher-name>Stanford University</publisher-name> Accessed July 2018. Available at <ext-link ext-link-type="uri" xlink:href="https://pdfs.semanticscholar.org/78a6/7f45aae9dd46c16fd10df668fddc39ed1bc1.pdf">https://pdfs.semanticscholar.org/78a6/7f45aae9dd46c16fd10df668fddc39ed1bc1.pdf</ext-link>.
</mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal">
<string-name><surname>Knutson</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Samanez-Larkin</surname>
<given-names>GR</given-names></string-name>, <string-name><surname>Kuhnen</surname>
<given-names>CM</given-names></string-name> (<year>2011</year>) <article-title>Gain and loss learning differentially contribute to life financial outcomes</article-title>. <source>PLoS One</source>
<volume>6</volume>:<fpage>e24390</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0024390</pub-id><pub-id pub-id-type="pmid">21915320</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal">
<string-name><surname>Krabbe</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Gr&#x000fc;ndemann</surname>
<given-names>J</given-names></string-name>, <string-name><surname>L&#x000fc;thi</surname>
<given-names>A</given-names></string-name> (<year>2017</year>) <article-title>Amygdala inhibitory circuits regulate associative fear conditioning</article-title>. <source>Biol Psychiatry</source>
<volume>83</volume>:<fpage>800</fpage>&#x02013;<lpage>809</lpage>.
<pub-id pub-id-type="pmid">29174478</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal">
<string-name><surname>Larkin</surname>
<given-names>JD</given-names></string-name>, <string-name><surname>Jenni</surname>
<given-names>NL</given-names></string-name>, <string-name><surname>Floresco</surname>
<given-names>SB</given-names></string-name> (<year>2016</year>) <article-title>Modulation of risk/reward decision making by dopaminergic transmission within the basolateral amygdala</article-title>. <source>Psychopharmacology (Berl)</source>
<volume>233</volume>:<fpage>121</fpage>&#x02013;<lpage>136</lpage>. <pub-id pub-id-type="doi">10.1007/s00213-015-4094-8</pub-id><pub-id pub-id-type="pmid">26432096</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal">
<string-name><surname>Namburi</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Beyeler</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Yorozu</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Calhoon</surname>
<given-names>GG</given-names></string-name>, <string-name><surname>Halbert</surname>
<given-names>SA</given-names></string-name>, <string-name><surname>Wichmann</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Holden</surname>
<given-names>SS</given-names></string-name>, <string-name><surname>Mertens</surname>
<given-names>KL</given-names></string-name>, <string-name><surname>Anahtar</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Felix-Ortiz</surname>
<given-names>AC</given-names></string-name>, <string-name><surname>Wickersham</surname>
<given-names>IR</given-names></string-name>, <string-name><surname>Gray</surname>
<given-names>JM</given-names></string-name>, <string-name><surname>Tye</surname>
<given-names>KM</given-names></string-name> (<year>2015</year>) <article-title>A circuit mechanism for differentiating positive and negative associations</article-title>. <source>Nature</source>
<volume>520</volume>:<fpage>675</fpage>&#x02013;<lpage>678</lpage>.
<pub-id pub-id-type="pmid">25925480</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal">
<string-name><surname>O&#x02019;Neill</surname>
<given-names>P-K</given-names></string-name>, <string-name><surname>Gore</surname>
<given-names>F</given-names></string-name>, <string-name><surname>Salzman</surname>
<given-names>CD</given-names></string-name> (<year>2018</year>) <article-title>Basolateral amygdala circuitry in positive and negative valence</article-title>. <source>Curr Opin Neurobiol</source>
<volume>49</volume>:<fpage>175</fpage>&#x02013;<lpage>183</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2018.02.012</pub-id>
<?supplied-pmid 29525574?><pub-id pub-id-type="pmid">29525574</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal">
<string-name><surname>Orsini</surname>
<given-names>CA</given-names></string-name>, <string-name><surname>Trotta</surname>
<given-names>RT</given-names></string-name>, <string-name><surname>Bizon</surname>
<given-names>JL</given-names></string-name>, <string-name><surname>Setlow</surname>
<given-names>B</given-names></string-name> (<year>2015</year>) <article-title>Dissociable roles for the basolateral amygdala and orbitofrontal cortex in decision-making under risk of punishment</article-title>. <source>J Neurosci</source>
<volume>35</volume>:<fpage>1368</fpage>&#x02013;<lpage>1379</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3586-14.2015</pub-id><pub-id pub-id-type="pmid">25632115</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal">
<string-name><surname>Orsini</surname>
<given-names>CA</given-names></string-name>, <string-name><surname>Hernandez</surname>
<given-names>CM</given-names></string-name>, <string-name><surname>Singhal</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Kelly</surname>
<given-names>KB</given-names></string-name>, <string-name><surname>Frazier</surname>
<given-names>CJ</given-names></string-name>, <string-name><surname>Bizon</surname>
<given-names>JL</given-names></string-name>, <string-name><surname>Setlow</surname>
<given-names>B</given-names></string-name> (<year>2017</year>) <article-title>Optogenetic inhibition reveals distinct roles for basolateral amygdala activity at discrete time points during risky decision making</article-title>. <source>J Neurosci</source>
<volume>37</volume>:<fpage>11537</fpage>&#x02013;<lpage>11548</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2344-17.2017</pub-id><pub-id pub-id-type="pmid">29079687</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal">
<string-name><surname>Piantadosi</surname>
<given-names>PT</given-names></string-name>, <string-name><surname>Yeates</surname>
<given-names>DCM</given-names></string-name>, <string-name><surname>Wilkins</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Floresco</surname>
<given-names>SB</given-names></string-name> (<year>2017</year>) <article-title>Contributions of basolateral amygdala and nucleus accumbens subregions to mediating motivational conflict during punished reward-seeking</article-title>. <source>Neurobiol Learn Mem</source>
<volume>140</volume>:<fpage>92</fpage>&#x02013;<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1016/j.nlm.2017.02.017</pub-id><pub-id pub-id-type="pmid">28242266</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book">
<string-name><surname>Preuschoff</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Mohr</surname>
<given-names>PNC</given-names></string-name>, <string-name><surname>Hsu</surname>
<given-names>M</given-names></string-name> (<year>2015</year>) <source>Decision making under uncertainty</source>. <publisher-loc>Lausanne</publisher-loc>: <publisher-name>Frontiers Media SA</publisher-name>.</mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal">
<string-name><surname>Pr&#x000e9;vost</surname>
<given-names>C</given-names></string-name>, <string-name><surname>McNamee</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Jessup</surname>
<given-names>RK</given-names></string-name>, <string-name><surname>Bossaerts</surname>
<given-names>P</given-names></string-name>, <string-name><surname>O'Doherty</surname>
<given-names>JP</given-names></string-name> (<year>2013</year>) <article-title>Evidence for model-based computations in the human amygdala during Pavlovian conditioning</article-title>. <source>PLoS Comput Biol</source>
<volume>9</volume>:<fpage>e1002918</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pcbi.1002918</pub-id><pub-id pub-id-type="pmid">23436990</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal">
<string-name><surname>Shabel</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Janak</surname>
<given-names>PH</given-names></string-name> (<year>2009</year>) <article-title>Substantial similarity in amygdala neuronal activity during conditioned appetitive and aversive emotional arousal</article-title>. <source>Proc Natl Acad Sci USA</source>
<volume>106</volume>:<fpage>15031</fpage>&#x02013;<lpage>15036</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0905580106</pub-id><pub-id pub-id-type="pmid">19706473</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal">
<string-name><surname>St Onge</surname>
<given-names>JR</given-names></string-name>, <string-name><surname>Stopper</surname>
<given-names>CM</given-names></string-name>, <string-name><surname>Zahm</surname>
<given-names>DS</given-names></string-name>, <string-name><surname>Floresco</surname>
<given-names>SB</given-names></string-name> (<year>2012</year>) <article-title>Separate prefrontal-subcortical circuits mediate different components of risk-based decision making</article-title>. <source>J Neurosci</source>
<volume>32</volume>:<fpage>2886</fpage>&#x02013;<lpage>2899</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5625-11.2012</pub-id><pub-id pub-id-type="pmid">22357871</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal">
<string-name><surname>Stopper</surname>
<given-names>CM</given-names></string-name>, <string-name><surname>Tse</surname>
<given-names>MTL</given-names></string-name>, <string-name><surname>Montes</surname>
<given-names>DR</given-names></string-name>, <string-name><surname>Wiedman</surname>
<given-names>CR</given-names></string-name>, <string-name><surname>Floresco</surname>
<given-names>SB</given-names></string-name> (<year>2014</year>) <article-title>Overriding phasic dopamine signals redirects action selection during risk/reward decision making</article-title>. <source>Neuron</source>
<volume>84</volume>:<fpage>177</fpage>&#x02013;<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.033</pub-id><pub-id pub-id-type="pmid">25220811</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal">
<string-name><surname>W&#x000e4;chter</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Lungu</surname>
<given-names>OV</given-names></string-name>, <string-name><surname>Liu</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Willingham</surname>
<given-names>DT</given-names></string-name>, <string-name><surname>Ashe</surname>
<given-names>J</given-names></string-name> (<year>2009</year>) <article-title>Differential effect of reward and punishment on procedural learning</article-title>. <source>J Neurosci</source>
<volume>29</volume>:<fpage>436</fpage>&#x02013;<lpage>443</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4132-08.2009</pub-id>
<?supplied-pmid 19144843?><pub-id pub-id-type="pmid">19144843</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="book">
<string-name><surname>Weber</surname>
<given-names>EU</given-names></string-name>, <string-name><surname>Johnson</surname>
<given-names>EJ</given-names></string-name> (<year>2009</year>) <chapter-title>Decisions under uncertainty</chapter-title> In: <source>Neuroeconomics</source>, pp <fpage>127</fpage>&#x02013;<lpage>144</lpage>. <publisher-loc>New York</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal">
<string-name><surname>Zalocusky</surname>
<given-names>KA</given-names></string-name>, <string-name><surname>Ramakrishnan</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Lerner</surname>
<given-names>TN</given-names></string-name>, <string-name><surname>Davidson</surname>
<given-names>TJ</given-names></string-name>, <string-name><surname>Knutson</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Deisseroth</surname>
<given-names>K</given-names></string-name> (<year>2016</year>) <article-title>Nucleus accumbens D2R cells signal prior outcomes and control risky decision-making</article-title>. <source>Nature</source>
<volume>531</volume>:<fpage>642</fpage>&#x02013;<lpage>646</lpage>. <pub-id pub-id-type="doi">10.1038/nature17400</pub-id><pub-id pub-id-type="pmid">27007845</pub-id></mixed-citation></ref></ref-list><sec sec-type="synthesis-author-response" id="s5"><title>Synthesis</title><boxed-text position="float" orientation="portrait"><p>Reviewing Editor: Carmen Sandi, Swiss Federal Institute of Technology</p><p>Decisions are customarily a result of the Reviewing Editor and the peer reviewers coming together and discussing their recommendations until a consensus is reached. When revisions are invited, a fact-based synthesis statement explaining their decision and outlining what is needed to prepare a revision will be listed below.</p></boxed-text><p>This Commentary on the report by Orsini et al. published in J. Neurosci. In 2017 is considered relevant and well formulated by an expert reviewer and the editor's own assessment. An increasing number of studies report that the basolateral amygdala is involved in multiple behavioral tasks, including learning, valence, anxiety and decision-making. This commentary provides a good synthesis and interesting insights on the role of the BLA in risky decision making, which will provide neuroscientists with a better understanding of the BLA in this specific behavior, in order to build a more integrative model of BLA function. However, we feel that the manuscript is lacking organization and structure, as well as some important conceptual and experimental clarifications.</p><p>Below, there is a detailed account of the points to consider and proposed changes:</p><p>Line 35: in the last sentence of this paragraph, the author mention the absence of experiments with temporal control of BLA activity. However, the author do not emphasize the importance of such manipulations. It is necessary to state that it remains unknown whether the BLA is involved in the decision making (deliberation phase) and/or in the associative phase of the reward and punishment.</p><p>Line 40: please specify that the &#x000ab; risky &#x000bb; reward is paired with a punishment as soon as you introduce it.</p><p>Line 44: It is important to define &#x02018;deliberation&#x02019;, in terms of time and choice: 10 second while the rats has to choose between two levers (safe and risky). Please also specify when the light inhibition is applied.</p><p>Line 65-66: Please define &#x02018;lose-shift performance&#x02019;. Interesting concepts developed include divergent roles of projection-defined populations of the BLA which could be specifically involved in the deliberating or associative phase (outcome). Indeed, only different projector-populations might be recruited during specific phases of the task, and therefore, inhibition of all projection neurons would have an impact only on the population which is normally activated during that phase. This concept should be explained more clearly.</p><p>The work of Burgos-Robles et al., 2017, assessing the role of the BLA-mPFC neurons while rats have to make conflicting choices could also be included in this projection-defined section.</p><p>Burgos-Robles, A., Kimchi, E.Y., Izadmehr, E.M., Porzenheim, M.J., Ramos-Guasp, W.A., Nieh, E.H., Felix-Ortiz, A.C., Namburi, P., Leppla, C.A., Presbrey, K.N., et al. (2017). Amygdala inputs to prefrontal cortex guide behavior amid conflicting cues of reward and punishment. Nat. Neurosci. 20, 824-835.</p><p>While describing the work of Beyeler et al. 2016, the wording could be improved to more precisely report their findings. Please consider the following change: Line 57: (NAc projectors) are preferentially excited to reward-predictive cues, whereas central amygdala (CeA) projectors are preferentially excited to cues associated with an aversive outcome.</p><p>Another possibility is that different inputs to the BLA are active at specific time points of the behavioral task and inhibition of the post-synaptic neurons would then have selective effects. In this context, dopaminergic inputs could be discussed, and (Larkin et al., 2016) should be cited.</p><p>Larkin, J.D., Jenni, N.L., and Floresco, S.B. (2016). Modulation of risk/reward decision making by dopaminergic transmission within the basolateral amygdala. Psychopharmacology (Berl.) 233, 121-136.</p><p>Finally, when describing three avenues of research, although interesting they are not grounded in the synthesis of the commentary, and feel really disconnected from the rest of the text and from each other.</p><p>Inter-individuality is indeed an important factor worth exploring, however, the concept needs to be introduced before.</p><p>Similarly, the third avenue is very unclear, and does not relate to any of the work described in the commentary. Moreover, how would DREADDS allow to do patterns of stimulations?</p><p>A summary diagram would also help the authors to better organize and communicate their hypotheses and proposed research directions.</p><p>Minor Comments________</p><p>Line 115: Plays different roles [at different behavioral phases] of risky decision making.</p><p>Line 126: &#x02018;it would be interesting to&#x02019; should be deleted = First, investigate whether the effects of...</p><p>Line 127: as a function &#x02018;OF&#x02019; individual differences.</p></sec></back></article>